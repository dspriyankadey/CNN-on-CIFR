{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DenseNet_cifar10_(3) (2).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wVIx_KIigxPV",
        "outputId": "5a3a1859-1a9b-469a-e70e-4550a774e17e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "# import keras\n",
        "# from keras.datasets import cifar10\n",
        "# from keras.models import Model, Sequential\n",
        "# from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
        "#from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "# from keras.layers import Concatenate\n",
        "# from keras.optimizers import Adam\n",
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation, Flatten,GlobalAveragePooling2D,AveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dsO_yGxcg5D8",
        "colab": {}
      },
      "source": [
        "# Hyperparameters\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 10\n",
        "l = 40\n",
        "num_filter = 12\n",
        "compression = 0.5\n",
        "#dropout_rate = 0.2\n",
        "weight_decay = 1e-4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mB7o3zu1g6eT",
        "outputId": "3e028107-a411-4499-9160-f94350290512",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Load CIFAR10 Data\n",
        "from sklearn.model_selection import train_test_split\n",
        "#from sklearn.utils import resample\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "img_height, img_width, channel = X_train.shape[1],X_train.shape[2],X_train.shape[3]\n",
        "\n",
        "X_train, X_cv, y_train, y_cv = train_test_split(X_train, y_train, test_size=0.20, random_state=42)\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes) \n",
        "y_cv = tf.keras.utils.to_categorical(y_cv, num_classes) "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmUkPEdWSgMu",
        "colab_type": "code",
        "outputId": "cc86c823-1761-4369-809f-977619dadbf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAEXUQs9xmiX",
        "colab_type": "code",
        "outputId": "3b6903c1-2a31-403f-ed6f-5aa222005ad2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_cv.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWmTvTi7SgMw",
        "colab_type": "code",
        "outputId": "f98de089-edd2-4397-807f-ec788de44674",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vHTEuJpOexes",
        "colab": {}
      },
      "source": [
        "# Dense Block\n",
        "#https://machinelearningmastery.com/weight-regularization-to-reduce-overfitting-of-deep-learning-models/\n",
        "def denseblock(input, num_filter = 12, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    global weight_decay\n",
        "    temp = input\n",
        "    input_conv1 = num_filter*4\n",
        "    for _ in range(l): \n",
        "        BatchNorm = layers.BatchNormalization(beta_regularizer=regularizers.l2(weight_decay))(temp)\n",
        "        relu = layers.Activation('relu')(BatchNorm)\n",
        "        Conv2D_3_3 = layers.Conv2D(int(input_conv1),1, padding='same',kernel_initializer=\"he_normal\",use_bias=False ,kernel_regularizer=regularizers.l2(weight_decay))(relu)\n",
        "\n",
        "        BatchNorm = layers.BatchNormalization(beta_regularizer=regularizers.l2(weight_decay))(Conv2D_3_3)\n",
        "        relu = layers.Activation('relu')(BatchNorm)\n",
        "        Conv2D_3_4 = layers.Conv2D(int(num_filter),3, padding='same',kernel_initializer=\"he_normal\",use_bias=False ,kernel_regularizer=regularizers.l2(weight_decay))(relu)\n",
        "\n",
        "        concat = layers.Concatenate()([temp,Conv2D_3_4])\n",
        "        \n",
        "        temp = concat\n",
        "        \n",
        "    return temp\n",
        "\n",
        "\n",
        "## transition Blosck\n",
        "#https://arthurdouillard.com/post/densenet/\n",
        "def transition(input, num_filter = 12, dropout_rate = 0.2):\n",
        "  \n",
        "    global compression\n",
        "    global weight_decay\n",
        "    channel = input.shape.as_list()[-1]\n",
        "    input_conv = channel*compression\n",
        "    BatchNorm = layers.BatchNormalization(beta_regularizer=regularizers.l2(weight_decay))(input)\n",
        "    relu = layers.Activation('relu')(BatchNorm)\n",
        "    Conv2D_BottleNeck = layers.Conv2D(int(input_conv), 1,use_bias=False ,padding='same',kernel_regularizer=regularizers.l2(weight_decay))(relu)\n",
        "    Conv2D_BottleNeck = layers.Activation('relu')(Conv2D_BottleNeck)\n",
        "    avg = layers.AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
        "    return avg\n",
        "\n",
        "\n",
        "# #output layer\n",
        "def output_layer(input):\n",
        "    input_conv = num_filter*1\n",
        "    BatchNorm = BatchNormalization(beta_regularizer=regularizers.l2(weight_decay))(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    AvgPooling = AveragePooling2D(pool_size=(8,8))(relu)\n",
        "    #output = layers.Conv2D(10,1,use_bias=False ,padding='same',kernel_regularizer=regularizers.l2(weight_decay))(AvgPooling)\n",
        "    #flat = Flatten()(AvgPooling)\n",
        "    output = layers.Conv2D(10,1,use_bias=False ,padding='same',kernel_regularizer=regularizers.l2(weight_decay))(AvgPooling)\n",
        "    output = Activation('softmax')(output)\n",
        "    #output = AveragePooling2D(pool_size=(1,1))(output)\n",
        "    output = Flatten()(output)\n",
        "    #output  = BatchNormalization(beta_regularizer=regularizers.l2(weight_decay))(output)\n",
        "   # output = Flatten()(output)\n",
        "   # output = layers.Conv2D(num_classes,2, activation='softmax',kernel_regularizer=regularizers.l2(weight_decay))(flat)\n",
        "   # output = layers.Dense(num_classes, activation='softmax')(flat)\n",
        "    return output\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "anPCpQWhhGb7",
        "outputId": "317b477c-9b51-4128-b611-81f4be6d2057",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "from tensorflow.keras import regularizers \n",
        "num_filter = 12\n",
        "dropout_rate = 0.2\n",
        "l = 16\n",
        "input = layers.Input(shape=(img_height, img_width, channel,))\n",
        "First_Conv2D = layers.Conv2D(2*num_filter, 3, use_bias=False ,padding='same',bias_initializer='zeros',kernel_regularizer=regularizers.l2(weight_decay))(input)\n",
        "\n",
        "First_Block = denseblock(First_Conv2D, num_filter, dropout_rate)\n",
        "First_Transition = transition(First_Block, num_filter, dropout_rate)\n",
        "\n",
        "Second_Block = denseblock(First_Transition, num_filter, dropout_rate)\n",
        "Second_Transition = transition(Second_Block, num_filter, dropout_rate)\n",
        "\n",
        "Third_Block = denseblock(Second_Transition, num_filter, dropout_rate)\n",
        "\n",
        "output = output_layer(Third_Block)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1kFh7pdxhNtT",
        "scrolled": true,
        "outputId": "ac046bff-926b-4b4b-82f6-50d0759b2d31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 13005
        }
      },
      "source": [
        "model1 = Model(inputs=[input], outputs=[output])\n",
        "model1.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 32, 32, 24)   648         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 32, 32, 24)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 32, 32, 24)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 48)   1152        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 48)   192         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 48)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 12)   5184        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 32, 32, 36)   0           conv2d[0][0]                     \n",
            "                                                                 conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 36)   144         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 36)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 48)   1728        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 48)   192         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 48)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 12)   5184        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 32, 32, 48)   0           concatenate[0][0]                \n",
            "                                                                 conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 48)   192         concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 48)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 48)   2304        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 48)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 32, 48)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 12)   5184        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 32, 32, 60)   0           concatenate_1[0][0]              \n",
            "                                                                 conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 60)   240         concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 32, 60)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 48)   2880        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32, 32, 48)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 32, 32, 48)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 32, 32, 12)   5184        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 32, 32, 72)   0           concatenate_2[0][0]              \n",
            "                                                                 conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 32, 32, 72)   288         concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 32, 32, 72)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 32, 32, 48)   3456        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 32, 32, 48)   192         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 32, 32, 48)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 32, 32, 12)   5184        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 32, 32, 84)   0           concatenate_3[0][0]              \n",
            "                                                                 conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 32, 32, 84)   336         concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 32, 32, 84)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 32, 32, 48)   4032        activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 32, 32, 48)   192         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 32, 32, 48)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 32, 32, 12)   5184        activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 32, 32, 96)   0           concatenate_4[0][0]              \n",
            "                                                                 conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 32, 32, 96)   384         concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 32, 32, 96)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 32, 32, 48)   4608        activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 32, 32, 48)   192         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 32, 32, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 32, 32, 12)   5184        activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 32, 32, 108)  0           concatenate_5[0][0]              \n",
            "                                                                 conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 32, 32, 108)  432         concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 32, 32, 108)  0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 32, 32, 48)   5184        activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 32, 32, 48)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 32, 32, 48)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 32, 32, 12)   5184        activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 32, 32, 120)  0           concatenate_6[0][0]              \n",
            "                                                                 conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 32, 32, 120)  480         concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 32, 32, 120)  0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 32, 32, 48)   5760        activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 32, 32, 48)   192         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 32, 32, 48)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 32, 32, 12)   5184        activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 32, 32, 132)  0           concatenate_7[0][0]              \n",
            "                                                                 conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 32, 32, 132)  528         concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 32, 32, 132)  0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 32, 32, 48)   6336        activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 32, 32, 48)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 32, 32, 48)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 32, 32, 12)   5184        activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 32, 32, 144)  0           concatenate_8[0][0]              \n",
            "                                                                 conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 32, 32, 144)  576         concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 32, 32, 144)  0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 32, 32, 48)   6912        activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 32, 32, 48)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 32, 32, 48)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 32, 32, 12)   5184        activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 32, 32, 156)  0           concatenate_9[0][0]              \n",
            "                                                                 conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 32, 32, 156)  624         concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 32, 32, 156)  0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 32, 32, 48)   7488        activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 32, 32, 48)   192         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 32, 32, 48)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 32, 32, 12)   5184        activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, 32, 32, 168)  0           concatenate_10[0][0]             \n",
            "                                                                 conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 32, 32, 168)  672         concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 32, 32, 168)  0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 32, 32, 48)   8064        activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 32, 32, 48)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 32, 32, 48)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 32, 32, 12)   5184        activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 32, 32, 180)  0           concatenate_11[0][0]             \n",
            "                                                                 conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 32, 32, 180)  720         concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 32, 32, 180)  0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 32, 32, 48)   8640        activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 32, 32, 48)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 32, 32, 48)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 32, 32, 12)   5184        activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_13 (Concatenate)    (None, 32, 32, 192)  0           concatenate_12[0][0]             \n",
            "                                                                 conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 32, 32, 192)  768         concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 32, 32, 192)  0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 32, 32, 48)   9216        activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 32, 32, 48)   192         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 32, 32, 48)   0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 32, 32, 12)   5184        activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_14 (Concatenate)    (None, 32, 32, 204)  0           concatenate_13[0][0]             \n",
            "                                                                 conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 32, 32, 204)  816         concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 32, 32, 204)  0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 32, 32, 48)   9792        activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 32, 32, 48)   192         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 32, 32, 48)   0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 32, 32, 12)   5184        activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_15 (Concatenate)    (None, 32, 32, 216)  0           concatenate_14[0][0]             \n",
            "                                                                 conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 32, 32, 216)  864         concatenate_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 32, 32, 216)  0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 32, 32, 108)  23328       activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 32, 32, 108)  0           conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 108)  0           activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 16, 16, 108)  432         average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 16, 16, 108)  0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 16, 16, 48)   5184        activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 16, 16, 48)   192         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 16, 16, 48)   0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 16, 16, 12)   5184        activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_16 (Concatenate)    (None, 16, 16, 120)  0           average_pooling2d[0][0]          \n",
            "                                                                 conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 16, 16, 120)  480         concatenate_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 16, 16, 120)  0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 16, 16, 48)   5760        activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 16, 16, 48)   192         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 16, 16, 48)   0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 16, 16, 12)   5184        activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_17 (Concatenate)    (None, 16, 16, 132)  0           concatenate_16[0][0]             \n",
            "                                                                 conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 16, 16, 132)  528         concatenate_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 16, 16, 132)  0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 16, 16, 48)   6336        activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 16, 16, 48)   192         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 16, 16, 48)   0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 16, 16, 12)   5184        activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_18 (Concatenate)    (None, 16, 16, 144)  0           concatenate_17[0][0]             \n",
            "                                                                 conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 16, 16, 144)  576         concatenate_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 16, 16, 144)  0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 16, 16, 48)   6912        activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 16, 16, 48)   192         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 16, 16, 48)   0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 16, 16, 12)   5184        activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_19 (Concatenate)    (None, 16, 16, 156)  0           concatenate_18[0][0]             \n",
            "                                                                 conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 16, 16, 156)  624         concatenate_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 16, 16, 156)  0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 16, 16, 48)   7488        activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 16, 16, 48)   192         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 16, 16, 48)   0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 16, 16, 12)   5184        activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_20 (Concatenate)    (None, 16, 16, 168)  0           concatenate_19[0][0]             \n",
            "                                                                 conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 16, 16, 168)  672         concatenate_20[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 16, 16, 168)  0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 16, 16, 48)   8064        activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 16, 16, 48)   192         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 16, 16, 48)   0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 16, 16, 12)   5184        activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_21 (Concatenate)    (None, 16, 16, 180)  0           concatenate_20[0][0]             \n",
            "                                                                 conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 16, 16, 180)  720         concatenate_21[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 16, 16, 180)  0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 16, 16, 48)   8640        activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 16, 16, 48)   192         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 16, 16, 48)   0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 16, 16, 12)   5184        activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_22 (Concatenate)    (None, 16, 16, 192)  0           concatenate_21[0][0]             \n",
            "                                                                 conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 16, 16, 192)  768         concatenate_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 16, 16, 192)  0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 16, 16, 48)   9216        activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 16, 16, 48)   192         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 16, 16, 48)   0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 16, 16, 12)   5184        activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_23 (Concatenate)    (None, 16, 16, 204)  0           concatenate_22[0][0]             \n",
            "                                                                 conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 16, 16, 204)  816         concatenate_23[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 16, 16, 204)  0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 16, 16, 48)   9792        activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 16, 16, 48)   192         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 16, 16, 48)   0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 16, 16, 12)   5184        activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_24 (Concatenate)    (None, 16, 16, 216)  0           concatenate_23[0][0]             \n",
            "                                                                 conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 16, 16, 216)  864         concatenate_24[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 16, 16, 216)  0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 16, 16, 48)   10368       activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 16, 16, 48)   192         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 16, 16, 48)   0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 16, 16, 12)   5184        activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_25 (Concatenate)    (None, 16, 16, 228)  0           concatenate_24[0][0]             \n",
            "                                                                 conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 16, 16, 228)  912         concatenate_25[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 16, 16, 228)  0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 16, 16, 48)   10944       activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 16, 16, 48)   192         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 16, 16, 48)   0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 16, 16, 12)   5184        activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_26 (Concatenate)    (None, 16, 16, 240)  0           concatenate_25[0][0]             \n",
            "                                                                 conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 16, 16, 240)  960         concatenate_26[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 16, 16, 240)  0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 16, 16, 48)   11520       activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 16, 16, 48)   192         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 16, 16, 48)   0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 16, 16, 12)   5184        activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_27 (Concatenate)    (None, 16, 16, 252)  0           concatenate_26[0][0]             \n",
            "                                                                 conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 16, 16, 252)  1008        concatenate_27[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 16, 16, 252)  0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 16, 16, 48)   12096       activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 16, 16, 48)   192         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 16, 16, 48)   0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 16, 16, 12)   5184        activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_28 (Concatenate)    (None, 16, 16, 264)  0           concatenate_27[0][0]             \n",
            "                                                                 conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 16, 16, 264)  1056        concatenate_28[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 16, 16, 264)  0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 16, 16, 48)   12672       activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 16, 16, 48)   192         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 16, 16, 48)   0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 16, 16, 12)   5184        activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_29 (Concatenate)    (None, 16, 16, 276)  0           concatenate_28[0][0]             \n",
            "                                                                 conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 16, 16, 276)  1104        concatenate_29[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 16, 16, 276)  0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 16, 16, 48)   13248       activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 16, 16, 48)   192         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 16, 16, 48)   0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 16, 16, 12)   5184        activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_30 (Concatenate)    (None, 16, 16, 288)  0           concatenate_29[0][0]             \n",
            "                                                                 conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 16, 16, 288)  1152        concatenate_30[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 16, 16, 288)  0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 16, 16, 48)   13824       activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 16, 16, 48)   192         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 16, 16, 48)   0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 16, 16, 12)   5184        activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_31 (Concatenate)    (None, 16, 16, 300)  0           concatenate_30[0][0]             \n",
            "                                                                 conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 16, 16, 300)  1200        concatenate_31[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 16, 16, 300)  0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 16, 16, 150)  45000       activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 16, 16, 150)  0           conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 8, 8, 150)    0           activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 8, 8, 150)    600         average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 8, 8, 150)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 8, 8, 48)     7200        activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 8, 8, 48)     192         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 8, 8, 48)     0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 8, 8, 12)     5184        activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_32 (Concatenate)    (None, 8, 8, 162)    0           average_pooling2d_1[0][0]        \n",
            "                                                                 conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 8, 8, 162)    648         concatenate_32[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 8, 8, 162)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 8, 8, 48)     7776        activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 8, 8, 48)     192         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 8, 8, 48)     0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 8, 8, 12)     5184        activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_33 (Concatenate)    (None, 8, 8, 174)    0           concatenate_32[0][0]             \n",
            "                                                                 conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 8, 8, 174)    696         concatenate_33[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 8, 8, 174)    0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 8, 8, 48)     8352        activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 8, 8, 48)     192         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 8, 8, 48)     0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 8, 8, 12)     5184        activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_34 (Concatenate)    (None, 8, 8, 186)    0           concatenate_33[0][0]             \n",
            "                                                                 conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 8, 8, 186)    744         concatenate_34[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 8, 8, 186)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 8, 8, 48)     8928        activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 8, 8, 48)     192         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 8, 8, 48)     0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 8, 8, 12)     5184        activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_35 (Concatenate)    (None, 8, 8, 198)    0           concatenate_34[0][0]             \n",
            "                                                                 conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 8, 8, 198)    792         concatenate_35[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 8, 8, 198)    0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 8, 8, 48)     9504        activation_76[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 8, 8, 48)     192         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 8, 8, 48)     0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 8, 8, 12)     5184        activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_36 (Concatenate)    (None, 8, 8, 210)    0           concatenate_35[0][0]             \n",
            "                                                                 conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 8, 8, 210)    840         concatenate_36[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 8, 8, 210)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 8, 8, 48)     10080       activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 8, 8, 48)     192         conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 8, 8, 48)     0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 8, 8, 12)     5184        activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_37 (Concatenate)    (None, 8, 8, 222)    0           concatenate_36[0][0]             \n",
            "                                                                 conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 8, 8, 222)    888         concatenate_37[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 8, 8, 222)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 8, 8, 48)     10656       activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 8, 8, 48)     192         conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 8, 8, 48)     0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 8, 8, 12)     5184        activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_38 (Concatenate)    (None, 8, 8, 234)    0           concatenate_37[0][0]             \n",
            "                                                                 conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 8, 8, 234)    936         concatenate_38[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 8, 8, 234)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 8, 8, 48)     11232       activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 8, 8, 48)     192         conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 8, 8, 48)     0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 8, 8, 12)     5184        activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_39 (Concatenate)    (None, 8, 8, 246)    0           concatenate_38[0][0]             \n",
            "                                                                 conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 8, 8, 246)    984         concatenate_39[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 8, 8, 246)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 8, 8, 48)     11808       activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 8, 8, 48)     192         conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 8, 8, 48)     0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 8, 8, 12)     5184        activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_40 (Concatenate)    (None, 8, 8, 258)    0           concatenate_39[0][0]             \n",
            "                                                                 conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 8, 8, 258)    1032        concatenate_40[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 8, 8, 258)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 8, 8, 48)     12384       activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 8, 8, 48)     192         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 8, 8, 48)     0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 8, 8, 12)     5184        activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_41 (Concatenate)    (None, 8, 8, 270)    0           concatenate_40[0][0]             \n",
            "                                                                 conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 8, 8, 270)    1080        concatenate_41[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 8, 8, 270)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 8, 8, 48)     12960       activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 8, 8, 48)     192         conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 8, 8, 48)     0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 8, 8, 12)     5184        activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_42 (Concatenate)    (None, 8, 8, 282)    0           concatenate_41[0][0]             \n",
            "                                                                 conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 8, 8, 282)    1128        concatenate_42[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 8, 8, 282)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 8, 8, 48)     13536       activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 8, 8, 48)     192         conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 8, 8, 48)     0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 8, 8, 12)     5184        activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_43 (Concatenate)    (None, 8, 8, 294)    0           concatenate_42[0][0]             \n",
            "                                                                 conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 8, 8, 294)    1176        concatenate_43[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 8, 8, 294)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 8, 8, 48)     14112       activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 8, 8, 48)     192         conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 8, 8, 48)     0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 8, 8, 12)     5184        activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_44 (Concatenate)    (None, 8, 8, 306)    0           concatenate_43[0][0]             \n",
            "                                                                 conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 8, 8, 306)    1224        concatenate_44[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 8, 8, 306)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 8, 8, 48)     14688       activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 8, 8, 48)     192         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 8, 8, 48)     0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 8, 8, 12)     5184        activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_45 (Concatenate)    (None, 8, 8, 318)    0           concatenate_44[0][0]             \n",
            "                                                                 conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 8, 8, 318)    1272        concatenate_45[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 8, 8, 318)    0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 8, 8, 48)     15264       activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_95 (BatchNo (None, 8, 8, 48)     192         conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 8, 8, 48)     0           batch_normalization_95[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 8, 8, 12)     5184        activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_46 (Concatenate)    (None, 8, 8, 330)    0           concatenate_45[0][0]             \n",
            "                                                                 conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_96 (BatchNo (None, 8, 8, 330)    1320        concatenate_46[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 8, 8, 330)    0           batch_normalization_96[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 8, 8, 48)     15840       activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_97 (BatchNo (None, 8, 8, 48)     192         conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_99 (Activation)      (None, 8, 8, 48)     0           batch_normalization_97[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, 8, 8, 12)     5184        activation_99[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_47 (Concatenate)    (None, 8, 8, 342)    0           concatenate_46[0][0]             \n",
            "                                                                 conv2d_98[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_98 (BatchNo (None, 8, 8, 342)    1368        concatenate_47[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_100 (Activation)     (None, 8, 8, 342)    0           batch_normalization_98[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 1, 1, 342)    0           activation_100[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_99 (Conv2D)              (None, 1, 1, 10)     3420        average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_101 (Activation)     (None, 1, 1, 10)     0           conv2d_99[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 10)           0           activation_101[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 793,140\n",
            "Trainable params: 769,152\n",
            "Non-trainable params: 23,988\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACN0TrdYgiPu",
        "colab_type": "code",
        "outputId": "48501082-2641-4838-e2f3-098a7e30eb3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#https://www.pyimagesearch.com/2019/07/08/keras-imagedatagenerator-and-data-augmentation/\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    zoom_range=0.32,\n",
        "    rotation_range=18,\n",
        " #   height_shift_range=0.1,\n",
        "#     width_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "   # vertical_flip=True,\n",
        "    rescale=1./255,\n",
        "    fill_mode='nearest')\n",
        "\n",
        "cv_datagen = ImageDataGenerator(\n",
        "  #  zoom_range=0.32,\n",
        "  #  rotation_range=18,\n",
        " #   height_shift_range=0.1,\n",
        "#     width_shift_range=0.1,\n",
        "  #  horizontal_flip=True,\n",
        "   # vertical_flip=True,\n",
        "    rescale=1./255,\n",
        "#    fill_mode='nearest'\n",
        "    )\n",
        "test_datagen = ImageDataGenerator(\n",
        "   # zoom_range=0.32,\n",
        " #   rotation_range=18,\n",
        " #   height_shift_range=0.1,\n",
        "#     width_shift_range=0.1,\n",
        "  #  horizontal_flip=True,\n",
        "   # vertical_flip=True,\n",
        "    rescale=1./255,\n",
        "   # fill_mode='nearest'\n",
        "    )"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsRm-hhggj6o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_datagen.fit(X_train)\n",
        "cv_datagen.fit(X_cv)\n",
        "test_datagen.fit(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3MLMnCOhhxI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://machinelearningmastery.com/how-to-control-the-speed-and-stability-of-training-neural-networks-with-gradient-descent-batch-size/\n",
        "epochs = 100\n",
        "batch_size = 64\n",
        "val_batch_size = 64\n",
        "steps_per_epoch= len(y_train)//batch_size\n",
        "validation_steps = len(y_test)//val_batch_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqYfm5qUiySo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "filepath = \"saved-model-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=False, mode='max')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txjx2C-i8urr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1 = Model(inputs=[input], outputs=[output])\n",
        "\n",
        "\n",
        "model1.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.RMSprop(lr=0.001,decay=1e-8),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqTP7cb4dFTa",
        "colab_type": "code",
        "outputId": "61cb900c-f072-4b77-f011-404affccb298",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model1.fit_generator(train_datagen.flow(X_train, y_train ,batch_size=128\n",
        " ),steps_per_epoch=steps_per_epoch,\n",
        "                    epochs=79,\n",
        "                    validation_data=cv_datagen.flow(X_cv,y_cv,batch_size=128),validation_steps = validation_steps,callbacks = [checkpoint])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/79\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "624/625 [============================>.] - ETA: 0s - loss: 2.2557 - acc: 0.3874Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 37s - loss: 2.1081 - acc: 0.3667\n",
            "Epoch 00001: saving model to saved-model-01-0.37.hdf5\n",
            "625/625 [==============================] - 280s 448ms/step - loss: 2.2554 - acc: 0.3875 - val_loss: 2.1081 - val_acc: 0.3667\n",
            "Epoch 2/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 1.8653 - acc: 0.4830Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 1.7780 - acc: 0.4872\n",
            "Epoch 00002: saving model to saved-model-02-0.49.hdf5\n",
            "625/625 [==============================] - 169s 270ms/step - loss: 1.8651 - acc: 0.4831 - val_loss: 1.7780 - val_acc: 0.4872\n",
            "Epoch 3/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 1.6030 - acc: 0.5751Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 1.5898 - acc: 0.5667\n",
            "Epoch 00003: saving model to saved-model-03-0.57.hdf5\n",
            "625/625 [==============================] - 168s 268ms/step - loss: 1.6028 - acc: 0.5752 - val_loss: 1.5898 - val_acc: 0.5667\n",
            "Epoch 4/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 1.3777 - acc: 0.6518Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 1.3909 - acc: 0.6286\n",
            "Epoch 00004: saving model to saved-model-04-0.63.hdf5\n",
            "625/625 [==============================] - 167s 268ms/step - loss: 1.3775 - acc: 0.6520 - val_loss: 1.3909 - val_acc: 0.6286\n",
            "Epoch 5/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 1.2012 - acc: 0.7121Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 1.2307 - acc: 0.6983\n",
            "Epoch 00005: saving model to saved-model-05-0.70.hdf5\n",
            "625/625 [==============================] - 167s 268ms/step - loss: 1.2011 - acc: 0.7121 - val_loss: 1.2307 - val_acc: 0.6983\n",
            "Epoch 6/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 1.0784 - acc: 0.7522Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 1.1183 - acc: 0.7353\n",
            "Epoch 00006: saving model to saved-model-06-0.74.hdf5\n",
            "625/625 [==============================] - 167s 267ms/step - loss: 1.0784 - acc: 0.7522 - val_loss: 1.1183 - val_acc: 0.7353\n",
            "Epoch 7/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.9919 - acc: 0.7794Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 1.0627 - acc: 0.7587\n",
            "Epoch 00007: saving model to saved-model-07-0.76.hdf5\n",
            "625/625 [==============================] - 167s 268ms/step - loss: 0.9920 - acc: 0.7793 - val_loss: 1.0627 - val_acc: 0.7587\n",
            "Epoch 8/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.9312 - acc: 0.7983Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 1.1308 - acc: 0.7305\n",
            "Epoch 00008: saving model to saved-model-08-0.73.hdf5\n",
            "625/625 [==============================] - 167s 267ms/step - loss: 0.9309 - acc: 0.7984 - val_loss: 1.1308 - val_acc: 0.7305\n",
            "Epoch 9/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.8867 - acc: 0.8119Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 0.9370 - acc: 0.7958\n",
            "Epoch 00009: saving model to saved-model-09-0.80.hdf5\n",
            "625/625 [==============================] - 168s 268ms/step - loss: 0.8867 - acc: 0.8119 - val_loss: 0.9370 - val_acc: 0.7958\n",
            "Epoch 10/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.8524 - acc: 0.8244Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 1.0095 - acc: 0.7702\n",
            "Epoch 00010: saving model to saved-model-10-0.77.hdf5\n",
            "625/625 [==============================] - 167s 267ms/step - loss: 0.8523 - acc: 0.8244 - val_loss: 1.0095 - val_acc: 0.7702\n",
            "Epoch 11/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.8217 - acc: 0.8336Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 0.8982 - acc: 0.8069\n",
            "Epoch 00011: saving model to saved-model-11-0.81.hdf5\n",
            "625/625 [==============================] - 167s 268ms/step - loss: 0.8216 - acc: 0.8336 - val_loss: 0.8982 - val_acc: 0.8069\n",
            "Epoch 12/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.7964 - acc: 0.8417Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 1.0971 - acc: 0.7502\n",
            "Epoch 00012: saving model to saved-model-12-0.75.hdf5\n",
            "625/625 [==============================] - 167s 268ms/step - loss: 0.7965 - acc: 0.8417 - val_loss: 1.0971 - val_acc: 0.7502\n",
            "Epoch 13/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.7735 - acc: 0.8487Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 29s - loss: 0.9737 - acc: 0.7875\n",
            "Epoch 00013: saving model to saved-model-13-0.79.hdf5\n",
            "625/625 [==============================] - 168s 269ms/step - loss: 0.7737 - acc: 0.8486 - val_loss: 0.9737 - val_acc: 0.7875\n",
            "Epoch 14/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.7592 - acc: 0.8537Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 0.7937 - acc: 0.8444\n",
            "Epoch 00014: saving model to saved-model-14-0.84.hdf5\n",
            "625/625 [==============================] - 168s 269ms/step - loss: 0.7591 - acc: 0.8537 - val_loss: 0.7937 - val_acc: 0.8444\n",
            "Epoch 15/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.7411 - acc: 0.8591Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 1.0268 - acc: 0.7751\n",
            "Epoch 00015: saving model to saved-model-15-0.78.hdf5\n",
            "625/625 [==============================] - 168s 269ms/step - loss: 0.7410 - acc: 0.8591 - val_loss: 1.0268 - val_acc: 0.7751\n",
            "Epoch 16/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.7312 - acc: 0.8632Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 0.8763 - acc: 0.8140\n",
            "Epoch 00016: saving model to saved-model-16-0.81.hdf5\n",
            "625/625 [==============================] - 168s 269ms/step - loss: 0.7313 - acc: 0.8632 - val_loss: 0.8763 - val_acc: 0.8140\n",
            "Epoch 17/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.7164 - acc: 0.8682Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 29s - loss: 0.7858 - acc: 0.8435\n",
            "Epoch 00017: saving model to saved-model-17-0.84.hdf5\n",
            "625/625 [==============================] - 168s 269ms/step - loss: 0.7163 - acc: 0.8682 - val_loss: 0.7858 - val_acc: 0.8435\n",
            "Epoch 18/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.7065 - acc: 0.8720Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 0.7814 - acc: 0.8481\n",
            "Epoch 00018: saving model to saved-model-18-0.85.hdf5\n",
            "625/625 [==============================] - 168s 269ms/step - loss: 0.7065 - acc: 0.8720 - val_loss: 0.7814 - val_acc: 0.8481\n",
            "Epoch 19/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.6933 - acc: 0.8756Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 0.7825 - acc: 0.8490\n",
            "Epoch 00019: saving model to saved-model-19-0.85.hdf5\n",
            "625/625 [==============================] - 168s 268ms/step - loss: 0.6933 - acc: 0.8756 - val_loss: 0.7825 - val_acc: 0.8490\n",
            "Epoch 20/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.6841 - acc: 0.8787Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 0.8871 - acc: 0.8199\n",
            "Epoch 00020: saving model to saved-model-20-0.82.hdf5\n",
            "625/625 [==============================] - 168s 268ms/step - loss: 0.6840 - acc: 0.8788 - val_loss: 0.8871 - val_acc: 0.8199\n",
            "Epoch 21/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.6758 - acc: 0.8797Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 1.1536 - acc: 0.7398\n",
            "Epoch 00021: saving model to saved-model-21-0.74.hdf5\n",
            "625/625 [==============================] - 167s 268ms/step - loss: 0.6759 - acc: 0.8796 - val_loss: 1.1536 - val_acc: 0.7398\n",
            "Epoch 22/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.6691 - acc: 0.8828Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 0.9084 - acc: 0.8043\n",
            "Epoch 00022: saving model to saved-model-22-0.80.hdf5\n",
            "625/625 [==============================] - 167s 268ms/step - loss: 0.6691 - acc: 0.8828 - val_loss: 0.9084 - val_acc: 0.8043\n",
            "Epoch 23/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.6612 - acc: 0.8842Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 0.9698 - acc: 0.7950\n",
            "Epoch 00023: saving model to saved-model-23-0.80.hdf5\n",
            "625/625 [==============================] - 167s 267ms/step - loss: 0.6611 - acc: 0.8842 - val_loss: 0.9698 - val_acc: 0.7950\n",
            "Epoch 24/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.6498 - acc: 0.8891Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 1.0687 - acc: 0.7668\n",
            "Epoch 00024: saving model to saved-model-24-0.77.hdf5\n",
            "625/625 [==============================] - 167s 267ms/step - loss: 0.6499 - acc: 0.8891 - val_loss: 1.0687 - val_acc: 0.7668\n",
            "Epoch 25/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.6451 - acc: 0.8893Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 0.9187 - acc: 0.8117\n",
            "Epoch 00025: saving model to saved-model-25-0.81.hdf5\n",
            "625/625 [==============================] - 167s 267ms/step - loss: 0.6450 - acc: 0.8893 - val_loss: 0.9187 - val_acc: 0.8117\n",
            "Epoch 26/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.6444 - acc: 0.8903Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 1.0219 - acc: 0.7823\n",
            "Epoch 00026: saving model to saved-model-26-0.78.hdf5\n",
            "625/625 [==============================] - 167s 267ms/step - loss: 0.6444 - acc: 0.8902 - val_loss: 1.0219 - val_acc: 0.7823\n",
            "Epoch 27/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.6339 - acc: 0.8934Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 0.8517 - acc: 0.8237\n",
            "Epoch 00027: saving model to saved-model-27-0.82.hdf5\n",
            "625/625 [==============================] - 168s 268ms/step - loss: 0.6340 - acc: 0.8934 - val_loss: 0.8517 - val_acc: 0.8237\n",
            "Epoch 28/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.6319 - acc: 0.8934Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 29s - loss: 0.7467 - acc: 0.8597\n",
            "Epoch 00028: saving model to saved-model-28-0.86.hdf5\n",
            "625/625 [==============================] - 168s 269ms/step - loss: 0.6317 - acc: 0.8934 - val_loss: 0.7467 - val_acc: 0.8597\n",
            "Epoch 29/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.6230 - acc: 0.8965Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 0.7358 - acc: 0.8607\n",
            "Epoch 00029: saving model to saved-model-29-0.86.hdf5\n",
            "625/625 [==============================] - 168s 269ms/step - loss: 0.6232 - acc: 0.8965 - val_loss: 0.7358 - val_acc: 0.8607\n",
            "Epoch 30/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.6206 - acc: 0.8974Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 0.7596 - acc: 0.8529\n",
            "Epoch 00030: saving model to saved-model-30-0.85.hdf5\n",
            "625/625 [==============================] - 168s 268ms/step - loss: 0.6206 - acc: 0.8974 - val_loss: 0.7596 - val_acc: 0.8529\n",
            "Epoch 31/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.6164 - acc: 0.8985Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 0.7108 - acc: 0.8692\n",
            "Epoch 00031: saving model to saved-model-31-0.87.hdf5\n",
            "625/625 [==============================] - 168s 269ms/step - loss: 0.6164 - acc: 0.8985 - val_loss: 0.7108 - val_acc: 0.8692\n",
            "Epoch 32/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.6129 - acc: 0.9001Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 0.7158 - acc: 0.8684\n",
            "Epoch 00032: saving model to saved-model-32-0.87.hdf5\n",
            "625/625 [==============================] - 168s 269ms/step - loss: 0.6128 - acc: 0.9001 - val_loss: 0.7158 - val_acc: 0.8684\n",
            "Epoch 33/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.6037 - acc: 0.9025Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 0.9624 - acc: 0.7975\n",
            "Epoch 00033: saving model to saved-model-33-0.80.hdf5\n",
            "625/625 [==============================] - 168s 268ms/step - loss: 0.6036 - acc: 0.9025 - val_loss: 0.9624 - val_acc: 0.7975\n",
            "Epoch 34/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.6032 - acc: 0.9032Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 0.8483 - acc: 0.8368\n",
            "Epoch 00034: saving model to saved-model-34-0.84.hdf5\n",
            "625/625 [==============================] - 168s 268ms/step - loss: 0.6032 - acc: 0.9032 - val_loss: 0.8483 - val_acc: 0.8368\n",
            "Epoch 35/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.5969 - acc: 0.9046Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 0.8506 - acc: 0.8308\n",
            "Epoch 00035: saving model to saved-model-35-0.83.hdf5\n",
            "625/625 [==============================] - 168s 268ms/step - loss: 0.5969 - acc: 0.9046 - val_loss: 0.8506 - val_acc: 0.8308\n",
            "Epoch 36/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.5961 - acc: 0.9057Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 0.9631 - acc: 0.7976\n",
            "Epoch 00036: saving model to saved-model-36-0.80.hdf5\n",
            "625/625 [==============================] - 167s 268ms/step - loss: 0.5961 - acc: 0.9057 - val_loss: 0.9631 - val_acc: 0.7976\n",
            "Epoch 37/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.5897 - acc: 0.9068Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 0.7429 - acc: 0.8584\n",
            "Epoch 00037: saving model to saved-model-37-0.86.hdf5\n",
            "625/625 [==============================] - 167s 268ms/step - loss: 0.5897 - acc: 0.9068 - val_loss: 0.7429 - val_acc: 0.8584\n",
            "Epoch 38/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.5914 - acc: 0.9057Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 29s - loss: 0.6959 - acc: 0.8719\n",
            "Epoch 00038: saving model to saved-model-38-0.87.hdf5\n",
            "625/625 [==============================] - 168s 268ms/step - loss: 0.5914 - acc: 0.9058 - val_loss: 0.6959 - val_acc: 0.8719\n",
            "Epoch 39/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.5874 - acc: 0.9075Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 0.7007 - acc: 0.8700\n",
            "Epoch 00039: saving model to saved-model-39-0.87.hdf5\n",
            "625/625 [==============================] - 168s 269ms/step - loss: 0.5872 - acc: 0.9075 - val_loss: 0.7007 - val_acc: 0.8700\n",
            "Epoch 40/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.5830 - acc: 0.9081Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 0.7517 - acc: 0.8630\n",
            "Epoch 00040: saving model to saved-model-40-0.86.hdf5\n",
            "625/625 [==============================] - 167s 268ms/step - loss: 0.5831 - acc: 0.9081 - val_loss: 0.7517 - val_acc: 0.8630\n",
            "Epoch 41/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.5784 - acc: 0.9095Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 29s - loss: 0.7416 - acc: 0.8605\n",
            "Epoch 00041: saving model to saved-model-41-0.86.hdf5\n",
            "625/625 [==============================] - 168s 269ms/step - loss: 0.5785 - acc: 0.9095 - val_loss: 0.7416 - val_acc: 0.8605\n",
            "Epoch 42/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.5724 - acc: 0.9124Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 0.7041 - acc: 0.8723\n",
            "Epoch 00042: saving model to saved-model-42-0.87.hdf5\n",
            "625/625 [==============================] - 168s 269ms/step - loss: 0.5726 - acc: 0.9123 - val_loss: 0.7041 - val_acc: 0.8723\n",
            "Epoch 43/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.5709 - acc: 0.9114Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 0.7630 - acc: 0.8553\n",
            "Epoch 00043: saving model to saved-model-43-0.86.hdf5\n",
            "625/625 [==============================] - 168s 269ms/step - loss: 0.5712 - acc: 0.9113 - val_loss: 0.7630 - val_acc: 0.8553\n",
            "Epoch 44/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.5690 - acc: 0.9118Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 0.7748 - acc: 0.8530\n",
            "Epoch 00044: saving model to saved-model-44-0.85.hdf5\n",
            "625/625 [==============================] - 168s 268ms/step - loss: 0.5689 - acc: 0.9119 - val_loss: 0.7748 - val_acc: 0.8530\n",
            "Epoch 45/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.5687 - acc: 0.9117Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 0.9351 - acc: 0.8080\n",
            "Epoch 00045: saving model to saved-model-45-0.81.hdf5\n",
            "625/625 [==============================] - 167s 268ms/step - loss: 0.5687 - acc: 0.9117 - val_loss: 0.9351 - val_acc: 0.8080\n",
            "Epoch 46/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.5636 - acc: 0.9133Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 0.7407 - acc: 0.8562\n",
            "Epoch 00046: saving model to saved-model-46-0.86.hdf5\n",
            "625/625 [==============================] - 167s 268ms/step - loss: 0.5637 - acc: 0.9132 - val_loss: 0.7407 - val_acc: 0.8562\n",
            "Epoch 47/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.5550 - acc: 0.9148Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 29s - loss: 0.7127 - acc: 0.8688\n",
            "Epoch 00047: saving model to saved-model-47-0.87.hdf5\n",
            "625/625 [==============================] - 168s 268ms/step - loss: 0.5551 - acc: 0.9148 - val_loss: 0.7127 - val_acc: 0.8688\n",
            "Epoch 48/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.5547 - acc: 0.9164Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 0.6638 - acc: 0.8811\n",
            "Epoch 00048: saving model to saved-model-48-0.88.hdf5\n",
            "625/625 [==============================] - 168s 269ms/step - loss: 0.5547 - acc: 0.9165 - val_loss: 0.6638 - val_acc: 0.8811\n",
            "Epoch 49/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.5533 - acc: 0.9161Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 0.7735 - acc: 0.8512\n",
            "Epoch 00049: saving model to saved-model-49-0.85.hdf5\n",
            "625/625 [==============================] - 168s 268ms/step - loss: 0.5532 - acc: 0.9160 - val_loss: 0.7735 - val_acc: 0.8512\n",
            "Epoch 50/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.5544 - acc: 0.9161Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 0.9038 - acc: 0.8151\n",
            "Epoch 00050: saving model to saved-model-50-0.82.hdf5\n",
            "625/625 [==============================] - 167s 267ms/step - loss: 0.5544 - acc: 0.9161 - val_loss: 0.9038 - val_acc: 0.8151\n",
            "Epoch 51/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.5488 - acc: 0.9162Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 0.6980 - acc: 0.8739\n",
            "Epoch 00051: saving model to saved-model-51-0.87.hdf5\n",
            "625/625 [==============================] - 166s 266ms/step - loss: 0.5488 - acc: 0.9162 - val_loss: 0.6980 - val_acc: 0.8739\n",
            "Epoch 52/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.5477 - acc: 0.9178Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 0.8135 - acc: 0.8403\n",
            "Epoch 00052: saving model to saved-model-52-0.84.hdf5\n",
            "625/625 [==============================] - 167s 267ms/step - loss: 0.5476 - acc: 0.9179 - val_loss: 0.8135 - val_acc: 0.8403\n",
            "Epoch 53/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.5479 - acc: 0.9171Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 0.6889 - acc: 0.8738\n",
            "Epoch 00053: saving model to saved-model-53-0.87.hdf5\n",
            "625/625 [==============================] - 167s 268ms/step - loss: 0.5479 - acc: 0.9171 - val_loss: 0.6889 - val_acc: 0.8738\n",
            "Epoch 54/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.5413 - acc: 0.9191Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 0.8309 - acc: 0.8346\n",
            "Epoch 00054: saving model to saved-model-54-0.83.hdf5\n",
            "625/625 [==============================] - 167s 267ms/step - loss: 0.5413 - acc: 0.9191 - val_loss: 0.8309 - val_acc: 0.8346\n",
            "Epoch 55/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.5404 - acc: 0.9191Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 0.6638 - acc: 0.8823\n",
            "Epoch 00055: saving model to saved-model-55-0.88.hdf5\n",
            "625/625 [==============================] - 167s 267ms/step - loss: 0.5403 - acc: 0.9190 - val_loss: 0.6638 - val_acc: 0.8823\n",
            "Epoch 56/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.5405 - acc: 0.9185Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 0.8093 - acc: 0.8362\n",
            "Epoch 00056: saving model to saved-model-56-0.84.hdf5\n",
            "625/625 [==============================] - 167s 267ms/step - loss: 0.5405 - acc: 0.9185 - val_loss: 0.8093 - val_acc: 0.8362\n",
            "Epoch 57/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.5387 - acc: 0.9193Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 0.7815 - acc: 0.8506\n",
            "Epoch 00057: saving model to saved-model-57-0.85.hdf5\n",
            "625/625 [==============================] - 167s 267ms/step - loss: 0.5386 - acc: 0.9193 - val_loss: 0.7815 - val_acc: 0.8506\n",
            "Epoch 58/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.5308 - acc: 0.9212Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 29s - loss: 0.6707 - acc: 0.8816\n",
            "Epoch 00058: saving model to saved-model-58-0.88.hdf5\n",
            "625/625 [==============================] - 167s 267ms/step - loss: 0.5307 - acc: 0.9212 - val_loss: 0.6707 - val_acc: 0.8816\n",
            "Epoch 59/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.5339 - acc: 0.9207Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 0.7084 - acc: 0.8714\n",
            "Epoch 00059: saving model to saved-model-59-0.87.hdf5\n",
            "625/625 [==============================] - 166s 266ms/step - loss: 0.5339 - acc: 0.9207 - val_loss: 0.7084 - val_acc: 0.8714\n",
            "Epoch 60/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.5306 - acc: 0.9216Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 0.7675 - acc: 0.8531\n",
            "Epoch 00060: saving model to saved-model-60-0.85.hdf5\n",
            "625/625 [==============================] - 166s 266ms/step - loss: 0.5306 - acc: 0.9217 - val_loss: 0.7675 - val_acc: 0.8531\n",
            "Epoch 61/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.5321 - acc: 0.9205Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 0.6834 - acc: 0.8712\n",
            "Epoch 00061: saving model to saved-model-61-0.87.hdf5\n",
            "625/625 [==============================] - 166s 266ms/step - loss: 0.5320 - acc: 0.9205 - val_loss: 0.6834 - val_acc: 0.8712\n",
            "Epoch 62/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.5200 - acc: 0.9237Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 0.6302 - acc: 0.8912\n",
            "Epoch 00062: saving model to saved-model-62-0.89.hdf5\n",
            "625/625 [==============================] - 166s 266ms/step - loss: 0.5200 - acc: 0.9237 - val_loss: 0.6302 - val_acc: 0.8912\n",
            "Epoch 63/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.5232 - acc: 0.9231Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 0.6978 - acc: 0.8713\n",
            "Epoch 00063: saving model to saved-model-63-0.87.hdf5\n",
            "625/625 [==============================] - 166s 265ms/step - loss: 0.5231 - acc: 0.9231 - val_loss: 0.6978 - val_acc: 0.8713\n",
            "Epoch 64/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.5219 - acc: 0.9242Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 0.6460 - acc: 0.8831\n",
            "Epoch 00064: saving model to saved-model-64-0.88.hdf5\n",
            "625/625 [==============================] - 166s 265ms/step - loss: 0.5221 - acc: 0.9242 - val_loss: 0.6460 - val_acc: 0.8831\n",
            "Epoch 65/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.5206 - acc: 0.9241Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 27s - loss: 0.6259 - acc: 0.8929\n",
            "Epoch 00065: saving model to saved-model-65-0.89.hdf5\n",
            "625/625 [==============================] - 165s 264ms/step - loss: 0.5204 - acc: 0.9242 - val_loss: 0.6259 - val_acc: 0.8929\n",
            "Epoch 66/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.5193 - acc: 0.9235Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 0.6331 - acc: 0.8871\n",
            "Epoch 00066: saving model to saved-model-66-0.89.hdf5\n",
            "625/625 [==============================] - 165s 264ms/step - loss: 0.5193 - acc: 0.9235 - val_loss: 0.6331 - val_acc: 0.8871\n",
            "Epoch 67/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.5189 - acc: 0.9235Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 0.8078 - acc: 0.8344\n",
            "Epoch 00067: saving model to saved-model-67-0.83.hdf5\n",
            "625/625 [==============================] - 166s 266ms/step - loss: 0.5188 - acc: 0.9235 - val_loss: 0.8078 - val_acc: 0.8344\n",
            "Epoch 68/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.5133 - acc: 0.9256Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 0.6623 - acc: 0.8785\n",
            "Epoch 00068: saving model to saved-model-68-0.88.hdf5\n",
            "625/625 [==============================] - 168s 268ms/step - loss: 0.5135 - acc: 0.9256 - val_loss: 0.6623 - val_acc: 0.8785\n",
            "Epoch 69/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.5118 - acc: 0.9254Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 0.8297 - acc: 0.8240\n",
            "Epoch 00069: saving model to saved-model-69-0.82.hdf5\n",
            "625/625 [==============================] - 167s 268ms/step - loss: 0.5120 - acc: 0.9253 - val_loss: 0.8297 - val_acc: 0.8240\n",
            "Epoch 70/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.5108 - acc: 0.9263Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 0.6749 - acc: 0.8773\n",
            "Epoch 00070: saving model to saved-model-70-0.88.hdf5\n",
            "625/625 [==============================] - 166s 266ms/step - loss: 0.5110 - acc: 0.9262 - val_loss: 0.6749 - val_acc: 0.8773\n",
            "Epoch 71/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.5089 - acc: 0.9270Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 0.9044 - acc: 0.8196\n",
            "Epoch 00071: saving model to saved-model-71-0.82.hdf5\n",
            "625/625 [==============================] - 167s 266ms/step - loss: 0.5088 - acc: 0.9271 - val_loss: 0.9044 - val_acc: 0.8196\n",
            "Epoch 72/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.5099 - acc: 0.9262Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 0.6631 - acc: 0.8782\n",
            "Epoch 00072: saving model to saved-model-72-0.88.hdf5\n",
            "625/625 [==============================] - 166s 265ms/step - loss: 0.5098 - acc: 0.9262 - val_loss: 0.6631 - val_acc: 0.8782\n",
            "Epoch 73/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.5068 - acc: 0.9266Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 0.8167 - acc: 0.8418\n",
            "Epoch 00073: saving model to saved-model-73-0.84.hdf5\n",
            "625/625 [==============================] - 166s 266ms/step - loss: 0.5068 - acc: 0.9266 - val_loss: 0.8167 - val_acc: 0.8418\n",
            "Epoch 74/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.5051 - acc: 0.9275Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 0.5769 - acc: 0.9049\n",
            "Epoch 00074: saving model to saved-model-74-0.90.hdf5\n",
            "625/625 [==============================] - 166s 266ms/step - loss: 0.5050 - acc: 0.9275 - val_loss: 0.5769 - val_acc: 0.9049\n",
            "Epoch 75/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.5050 - acc: 0.9272Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 0.7149 - acc: 0.8632\n",
            "Epoch 00075: saving model to saved-model-75-0.86.hdf5\n",
            "625/625 [==============================] - 166s 266ms/step - loss: 0.5050 - acc: 0.9272 - val_loss: 0.7149 - val_acc: 0.8632\n",
            "Epoch 76/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.5033 - acc: 0.9269Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 0.6451 - acc: 0.8841\n",
            "Epoch 00076: saving model to saved-model-76-0.88.hdf5\n",
            "625/625 [==============================] - 167s 267ms/step - loss: 0.5032 - acc: 0.9269 - val_loss: 0.6451 - val_acc: 0.8841\n",
            "Epoch 77/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.5013 - acc: 0.9287Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 0.7071 - acc: 0.8687\n",
            "Epoch 00077: saving model to saved-model-77-0.87.hdf5\n",
            "625/625 [==============================] - 167s 267ms/step - loss: 0.5013 - acc: 0.9287 - val_loss: 0.7071 - val_acc: 0.8687\n",
            "Epoch 78/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.4993 - acc: 0.9285Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 0.6756 - acc: 0.8761\n",
            "Epoch 00078: saving model to saved-model-78-0.88.hdf5\n",
            "625/625 [==============================] - 167s 267ms/step - loss: 0.4993 - acc: 0.9285 - val_loss: 0.6756 - val_acc: 0.8761\n",
            "Epoch 79/79\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.4989 - acc: 0.9283Epoch 1/79\n",
            "156/625 [======>.......................] - ETA: 28s - loss: 0.6981 - acc: 0.8709\n",
            "Epoch 00079: saving model to saved-model-79-0.87.hdf5\n",
            "625/625 [==============================] - 167s 267ms/step - loss: 0.4987 - acc: 0.9284 - val_loss: 0.6981 - val_acc: 0.8709\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFdqEOLXQ8UQ",
        "colab_type": "code",
        "outputId": "180ac8ee-3bd2-40fb-9884-ea16670e4462",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "from keras.models import load_model\n",
        "best_model = tf.keras.models.load_model('saved-model-74-0.90.hdf5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LwG-Mxi5o9m",
        "colab_type": "text"
      },
      "source": [
        "##### From epoch 74 , accuracy value of cv data = 0.9064. So test model is evalutated based on this model value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMLn9KZzSzXo",
        "colab_type": "code",
        "outputId": "9feb7a40-5f30-4202-e151-17fdcf5d861d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# evaluate on test data\n",
        "score1 = best_model.evaluate_generator(test_datagen.flow(X_test, y_test, batch_size=64), verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 10s 64ms/step - loss: 0.5833 - acc: 0.9029\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZl90G7fS5zu",
        "colab_type": "code",
        "outputId": "f81ef704-7fde-43cb-bf20-3110c1f6d9d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "score1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5833201007858203, 0.9029]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJ93WrL5ANvm",
        "colab_type": "code",
        "outputId": "5a91845f-4586-4f0f-8067-3ab9fae7d182",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "import pylab as plt\n",
        "def plt_dynamic(x, vy, ty, ax, colors=['b']):\n",
        " ax.plot(x, vy, 'b', label=\"Train Loss\")\n",
        " ax.plot(x, ty, 'r', label=\"Validation Loss\")\n",
        " plt.legend()\n",
        " plt.grid()\n",
        " fig.canvas.draw()\n",
        "fig,ax = plt.subplots(1,1)\n",
        "ax.set_xlabel('epoch') ; ax.set_ylabel('Categorical Crossentropy Loss')\n",
        "# list of epoch numbers\n",
        "x = list(range(1,80))\n",
        "vy = history.history['loss']\n",
        "ty = history.history['val_loss']\n",
        "plt_dynamic(x, vy, ty, ax)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOydd3hUZfb4PychGCAh9ABBBKRDaEGq\nBdRFEAX1BwqKrq6K6xbLrm0VdV3d/eqqrLq6rnXtYmXByqpUBVGKFCnSpUmTltBSzu+PMzeZJDOT\nySSTScL7eZ73mbn3vve9Z2aSe+4p73lFVXE4HA6HoyhxsRbA4XA4HJUTpyAcDofDERCnIBwOh8MR\nEKcgHA6HwxEQpyAcDofDEZAasRagPGnUqJG2atUqrL5ZWVnUqVMnugJFiJMtMpxskeFki4zqItvC\nhQt3q2rjgAdVtdq0jIwMDZcZM2aE3beicbJFhpMtMpxskVFdZAMWaJB7qnMxORwOhyMgTkE4HA6H\nIyBOQTgcDocjINUqSO1wOKJPdnY2W7Zs4ciRI1G/VkpKCitXroz6dSKhqsmWmJhIixYtSEhICHsc\npyAcDkep2LJlC8nJybRq1QoRieq1Dh48SHJyclSvESlVSTZVZc+ePWzZsoXWrVuHPY5zMTkcjlJx\n5MgRGjZsGHXl4Cg/RISGDRuW2uqLmoIQkRNFZIaIrBCR70XkxgB9LhORpSKyTETmikh3v2Mbffu/\nE5EF0ZLT4XCUHqccqh6R/GbRdDHlAH9U1UUikgwsFJHPVHWFX58NwBmquldEhgHPAn39jg9W1d1R\nlBFVeOAB6NMHzjknmldyOByOqkXULAhV3a6qi3zvDwIrgbQifeaq6l7f5tdAi2jJEwwReOQR+Pjj\nir6yw+GIhD179tCjRw969OhB06ZNSUtLy98+duxYWGNcddVVrF69OuxrPv/889x0002RilxlEa2A\nBYNEpBUwG+iqqgeC9LkF6Kiq1/i2NwB7AQWeUdVng5w3HhgPkJqamjFp0qSwZMrMzCQpKQmAyy/v\nQ7t2mdxzz4oSzqoY/GWrbDjZIqM6yZaSkkLbtm2jKFEBubm5xMfHBz3+t7/9jaSkJG644YZC+/Nn\nAseVzzPwyy+/zIoVK3jooYfCli2WBJNt7dq17N+/v9C+wYMHL1TV3gEHCjbFurwakAQsBC4K0Wcw\nZmE09NuX5nttAiwBTi/pWpGW2jj1VNVBg8I+NepUlyn8FY2TLTJKK9uKFSuiI0gADhw4EPL4vffe\nqw8//LCqqq5Zs0Y7deqkl156qXbq1Em3bNmi1157rWZkZGjnzp31vvvuyz9v4MCBunjxYs3OztaU\nlBS9/fbbtVu3btqvXz/dsWNHses899xzeuONNxaT7dVXX9WuXbtqly5d9E9/+pOqqmZnZ+u4cePy\n9z/++OOqqjpx4kTt1KmTpqen62WXXVam76Ukgn1vgX47QpTaiGqaq4gkAO8Br6vq+0H6dAOeB4ap\n6h5vv6pu9b3uFJHJQB/MCil3UlNhReUwHhyOKsVNN8F335XvmD16wGOPRXbuqlWreOWVV+jd2x6I\nH3zwQRo0aEBOTg6DBw9m1KhRdO7cudA5+/fv54wzzuDBBx/kD3/4Ay+++CJ33HFHidfaunUrEyZM\nYMGCBaSkpHD22Wfz4Ycf0rhxY3bv3s2yZcsA2LdvHwB///vf2bRpEzVr1szfV9mJZhaTAC8AK1V1\nYpA+LYH3gctV9Qe//XV8gW1EpA4wBFgeLVmbNIGdO6M1usPhqChOPvnkfOUA8Oabb9KrVy969erF\nypUrWRHgSbBWrVoMGzYMgIyMDDZu3BjWtRYsWMCZZ55Jo0aNSEhI4NJLL2X27Nm0bduW1atXc8MN\nNzBt2jRSUlIA6NKlC+PGjeP1118v1WS1WBJNC2IgcDmwTES8Z4w7gZYAqvpv4B6gIfAvXwpWjpov\nLBWY7NtXA3hDVT+NlqCpqbBnD2RnQxX53RyOSkGkT/rRwr/E9Zo1a3j88cf55ptvqFevHuPGjQs4\nD6BmzZr57+Pj48nJySmTDA0bNmTp0qV88sknPPXUU7z33ns8++yzTJs2jVmzZjF16lT+9re/sXTp\n0kobw/CImoJQ1S+BkIm3agHpawLsXw90L35GdEhNtdddu6B584q6qsPhiCYHDhwgOTmZunXrsn37\ndqZNm8bQoUPLbfzevXtz9913s2fPHlJSUpg0aRK33HILu3btIjExkdGjR9OuXTuuueYacnNz2bJl\nC2eeeSannnoqJ554IocOHaq0M7E9XKkNChTEjh1OQTgc1YVevXrRuXNnOnbsyEknncTAgQPLNN4L\nL7zAu+++m789c+ZM7r//fgYNGoSqcv755zN8+HAWLVrE1VdfjaoiIjz00EPk5ORw6aWXcvDgQfLy\n8rjlllsqvXIApyAAi0GAi0M4HFWNP//5z/nv27Zty3d+EXMR4dVXXw143pdffpn/3j9gPGbMGMaM\nGVOs/zXXXMM11xR2dhw8eJBx48Yxbty4Qvt79erF4sWLi43x1Vdfhf4wlRBXi4nCFoTD4XA4DKcg\ncArC4XA4AuEUBJCUBLVqOQXhcDgc/jgFgdVjcnMhHA6HozBOQfhITXUWhMPhcPjjFIQPpyAcDoej\nME5B+Ehtok5BOBxVgMGDBzNt2rRC+x577DGuv/76kOd5FWu3bdvGqFGjAvYZNGgQCxaEXp/sscce\n49ChQ/nb5557brnUVvrzn//MI488UuZxyhOnIPLyoHlzLl11D7t22abD4ai8jB07lqJl/SdNmsTY\nsWPDOr958+aFJryVlqIK4uOPP6ZevXoRj1eZcQoiLg7i4kjN3kJuLvz8c6wFcjgcoRg1ahQfffRR\n/uJAGzduZNu2bZx22mlkZmZy1lln0atXL9LT05kyZUqx8zdu3EjXrl0BOHz4MGPGjKFTp05ceOGF\nHD58OL/f9ddfT+/evenSpQv33nsvAE888QTbtm1j8ODBDB8+HIBWrVqxe7ctfDlx4kS6du1K165d\necxXqGrjxo106tSJa6+9li5dujBkyJBC1ymJQGNmZWUxfPhwunfvTteuXXnrrbcAuOOOO+jcuTP9\n+/fnlltuKdX3Ggg3kxqgeXMaHN4KWByiUaMYy+NwVBViUO+7QYMG9OnTh08++YSRI0cyadIkLr74\nYkSExMREJk+eTN26ddm9ezf9+vVjxIgRQddjfvrpp6lduzYrV65k6dKl9OrVK//YX//6Vxo0aEBu\nbi5nnXUWS5cu5YYbbmDixInMmDGDE044odBYCxcu5D//+Q/z589HVenbty9nnHEG9evXZ82aNbz5\n5ps899xzXHzxxbz33nvFZmAHItiY69evp3nz5nz00UeAlSzfs2cPkydPZtWqVWRmZpKbmxvOtx0S\nZ0EApKWRfHAb4ALVDkdVwN/N5O9eUlXuvPNOunXrxtlnn83WrVvZEeKfevbs2fk36m7dutGtW7f8\nY2+//Ta9evWiZ8+efP/99wFLhfvz5ZdfcuGFF1KnTh2SkpK46KKLmDNnDgCtW7emR48eQOlKigcb\nMz09nc8++4zbb7+dOXPmkJKSQkpKComJiVx99dVMnTqV2rVrh3WNUDgLAiAtjcTpMwE3F8LhKBUx\nqvc9cuRIbr75ZhYtWsShQ4fIyMgA4PXXX2fXrl0sXLiQhIQEWrVqFbDEd0ls2LCBRx55hG+//Zb6\n9etz5ZVXRjSOh7+1ER8fXyoXUyDat2/PokWL+Pjjj5kwYQJnnXUW99xzD9988w1ffPEFb775Ji+8\n8ALTp08v03WcBQGQlkb8gX3U4pCzIByOKkBSUhKDBw/mV7/6VaHg9P79+2nSpAkJCQnMmDGDTZs2\nhRzn9NNP54033gBg+fLlLF26FLBS4XXq1CElJYUdO3bwySef5J+TnJzMwYMHi4112mmn8d///pdD\nhw6RlZXF5MmTOe2008r0OYONuW3bNmrXrs24ceO49dZbWbRoEZmZmezfv59zzz2X//u//2PJkiVl\nujY4C8JISwPgpPit7NjRLsbCOByOcBg7diwXXnhhoYymyy67jPPPP5/09HR69+5Nx44dQ45x/fXX\nc9VVV9GpUyc6deqUb4l0796dnj170rFjR0488cRCpcLHjx/P0KFDSU1NZfbsglWQe/XqxZVXXkmf\nPn0AqwDbs2fPsN1JAA888EB+IBpgy5YtAcecNm0at956K3FxcSQkJPD0009z8OBBRo4cyZEjR8jN\nzWXixIALeZaOYItVV8WWkZEReAXvABRaqP3zz1VBL2owQ3/1q7CHiBrVaYH7isTJFhmllS3QwvfR\n4sCBAxV2rdJSFWUL9NsBCzTIPdW5mCDfguiQtNXFIBwOh8OHUxCQryDaJG51MQiHw+HwUaKCEJHR\nIpLsez9BRN4XkV5hnHeiiMwQkRUi8r2I3Bigj4jIEyKyVkSW+o8rIr8UkTW+9svSfrBSkZwMycm0\njHMKwuEIB/NMOKoSkfxm4VgQd6vqQRE5FTgbeAF4OozzcoA/qmpnoB/wWxHpXKTPMKCdr433xhWR\nBsC9QF+gD3CviNQP45qRk5ZG01xTEO5v3+EITmJiInv27HFKogqhquzZs4fExMRSnRdOFpM3HW84\n8KyqfiQiD4Qh0HZgu+/9QRFZCaQB/rNNRgKv+AIlX4tIPRFpBgwCPlPVnwFE5DNgKPBmeB8rApo3\np+G6bRw9CgcPQt26UbuSw1GladGiBVu2bGHXrl1Rv9aRI0dKfVOrKKqabImJibRo0aJU44SjILaK\nyDPAL4CHROQEShm7EJFWQE9gfpFDacBmv+0tvn3B9gcaezxmfZCamsrMmTPDkikzM7NQ347x8dTe\nuxGAqVPn06JF2SaylIWislUmnGyR4WSLjMzMzPwqrJWNqihbSfNCihEsvclrQG3gIqCdb7sZMKSk\n8/zOTwIWAhcFOPYhcKrf9hdAb+AWYILf/ruBW0q6VsRprqqqd9yhufE1VMjVOXPCHiYqVKeUyIrE\nyRYZTrbIqC6yUcY012bAR6q6RkQGAaOBb8JRPiKSALwHvK6q7wfoshU40W+7hW9fsP3RIy2NuNwc\nGrPLBaodDoeD8FxF7wG5ItIWeBa7cb9R0kli5RNfAFaqarApfVOBK3zZTP2A/Wqxi2nAEBGp7wtO\nD/Htix6+VNc03FwIh8PhgPBiEHmqmiMiFwH/VNV/isjiMM4bCFwOLBMRrx7wnUBLAFX9N/AxcC6w\nFjgEXOU79rOI3A986zvvL+oLWEcNn4JowVZ27Cgxi9fhcDiqPeEoiGwRGQtcAZzv25dQ0kmq+iUQ\nuAh7QR8Ffhvk2IvAi2HIVz74FET7Om4uhMPhcEB4LqargP7AX1V1g4i0Bl6NrlgxIDUV4uJoW8sp\nCIfD4YAwFISqrsCyipaJSFdgi6o+FHXJKpoaNaBpU06q4WIQDofDAWG4mHyZSy8DGzGX0Yki8ktV\nnR3qvCpJWhrNN29zFoTD4XAQXgziUWzew2oAEWmPzWjOiKZgMaF5cxqvX+cUhMPhcBBeDCLBUw4A\nqvoDYQSpqyRpadQ/tJWDB6GMKwI6HA5HlSccBbFARJ4XkUG+9hywINqCxYS0NGod3ksih10cwuFw\nHPeEoyCuxwrs3eBrK4BfR1OomOE3Wc65mRwOx/FOiTEIVT0KTPQ1AETkLeCSKMoVGwopiLYxFsbh\ncDhiS6QryvUvVykqC86CcDgcjnzckqP++JXb2LIlxrI4HA5HjAnqYgqxrKhQXbOY6taFpCTas5U5\nG2ItjMPhcMSWUDGIR0McW1XeglQa0tI4ec82Xl4fa0EcDocjtgRVEKo6uCIFqTSkpdFi71Y2OAvC\n4XAc57gYRFGaN6fxsa1s3QpHjsRaGIfD4YgdTkEUJS2N5IPbEPLYuDHWwjgcDkfscAqiKGlpxOdm\n04jdrHdxCIfDcRxTooIQkfdFZLiIHB/KxG8uhFMQDofjeCacm/6/gEuBNSLyoIh0iLJMscWnINrU\ndArC4XAc34SzYNDnqnoZ0AtbE+JzEZkrIleJSPWbD+FTEN0aOgXhcDiOb8JyG4lIQ+BK4BpgMfA4\npjA+C3HOiyKyU0SWBzl+q4h852vLRSRXRBr4jm0UkWW+YxVbObZZM6hVix6Jq1yqq8PhOK4JJwYx\nGZgD1AbOV9URqvqWqv4eSApx6kvA0GAHVfVhVe2hqj2APwGzVPVnvy6Dfcd7h/NByo34eEhPp1P2\nEtavB9UKvbrD4XBUGsJZUe4JVZ0R6ECom7eqzhaRVmHKMRZbpa5y0L07Jy5/j8xDyu7dQuPGsRbI\n4XA4Kh7REh6RRSQR+A1wKqDAl8DTqlriNDKfgvhQVbuG6FMb2AK09SwIEdkA7PVd7xlVfTbE+eOB\n8QCpqakZkyZNKkksADIzM0lKCmwANZ88mfZPPEELNnPnUzvo3PlgWGOWF6FkizVOtshwskWGky0y\nSiPb4MGDFwZ92FfVkA14G3gBGOxrzwHvlHSe79xWwPIS+lwCfFBkX5rvtQmwBDg9nOtlZGRouMyY\nMSP4wTlzVEHP5UN9442whyw3QsoWY5xskeFkiwwnW2SURjZggQa5p4bjYuqqqp39tmeIyIqwVFN4\njKGIe0lVt/ped/piIH2A2eV4zdB06wZAD75j/frhFXZZh8PhqEyEk8W0SET6eRsi0pdyWpNaRFKA\nM4ApfvvqiEiy9x4YAgTMhIoadetCmzb0TVziUl0dDsdxSzgWRAYwV0R+9G23BFaLyDJAVbVboJNE\n5E1gENBIRLYA9+JbR0JV/+3rdiHwP1XN8js1FZgsIp58b6jqp6X6VOVB9+702LaEx1yqq8PhOE4J\nR0EETVUNhaqODaPPS1g6rP++9UD3SK5ZrnTvTovJ/2X72iygTqylcTgcjgonnJnUm4B6wPm+Vk9V\nN3kt2gLGjO7diUOpt2U5x47FWhiHw+GoeMKZKHcj8DqWUdQEeE1Efh9twWJOdzNiuul3/PhjCX0d\nDoejGhKOi+lqoK8XJxCRh4B5wD+jKVjMadWKnDp16Z5lgeq2bWMtkMPhcFQs4WQxCZDrt53r21e9\nESG3S3e64zKZHA7H8Uk4FsR/gPm++QgAF2AT56o9NU/pTrdvXuKD9Xm4tZUcDsfxRokKQlUnishM\nrNQGwFWqujiqUlUSpEd3kskkc9kG4ORYi+NwOBwVSkgFISLxwPeq2hFYVDEiVSJ8gerE1UtwCsLh\ncBxvhPSbqGouNimuZQXJU7no2pU8iaPJtu9iLYnD4XBUOOHEIOoD34vIN0D+jGdVHRE1qSoLtWqx\nt3F7Ouxcwt69UL9+rAVyOByOiiMcBXF31KWoxBxq34PuO+exfj1kZMRaGofD4ag4wknNOVdVZ/k3\n4NxoC1ZZqNGrO63YxI9L98VaFIfD4ahQwlEQvwiwb1h5C1JZqT/IAtUHv1oaY0kcDoejYgmqIETk\nel/F1g4istSvbQCWVZyIsSWxrykIXeoUhMPhOL4IFYN4A/gE+D/gDr/9B9W3NOhxQbNmHKhRn+QN\nx41OdDgcDiCEglDV/cB+YKxvPkSqr3+SiCSp6vFRwk6EHU3Saf7TclRBqn+REYfD4QDCq+b6O2AH\n8Bnwka99GGW5KhVHTu5Kp7zl/LRdYy2Kw+FwVBjhBKlvAjqoahdVTfe1gKvIVVdq9EwnhQNsmHV8\nGE0Oh8MB4SmIzZir6bilwRnpAOz7smKXxnY4HI5YEs5EufXATBH5CDjq7VTViVGTqpLReFAXAHK/\nWwYMj60wDofDUUGEY0H8iMUfagLJfi0kIvKiiOwUkYCP3SIySET2i8h3vnaP37GhIrJaRNaKyB2B\nzq9I4hrUY3vCidTZ4CwIh8Nx/BBOue/7AESktqoeKsXYLwFPAq+E6DNHVc/z3+HLmHoKm6C3BfhW\nRKaq6opSXLvc+alROs32uFRXh8Nx/BBOFlN/EVkBrPJtdxeRf5V0nqrOBiKZL9EHWKuq61X1GDAJ\nGBnBOOXKoTZdOfnYSg4fyI61KA6Hw1EhhBODeAw4B5gKoKpLROT0crp+fxFZAmwDblHV74E0LDDu\nsQXoG2wAERkPjAdITU1l5syZYV04MzMz7L4Auxs1oCbZvP/E+zQ4NTXs8yKhtLJVJE62yHCyRYaT\nLTLKTTZVDdmA+b7XxX77lpR0nq9fK2B5kGN1gSTf+3OBNb73o4Dn/fpdDjwZzvUyMjI0XGbMmBF2\nX1XVVZMWq4LOu2lSqc6LhNLKVpE42SLDyRYZTrbIKI1swAINck8NK81VRAYAKiIJInILsLIcFNMB\nVc30vf8YSBCRRsBW4ES/ri18+2JKi190Iod4she7QLXD4Tg+CEdB/Br4Leb62Qr08G2XCRFpKmKF\nK0Skj0+WPcC3QDsRaS0iNYEx+NxbsaROgxPYUKM9tde5QLXD4Tg+CCeLaTdwWWkHFpE3gUFAIxHZ\nAtwLJPjG/DfmSrpeRHKAw8AYn7mT4yvvMQ2IB15Ui03EnG0Nu3LyroWxFsPhcDgqhBIVhIj8HXgA\nu4l/CnQDblbV10Kdp6pjSzj+JJYGG+jYx8DHJclW0RxslU6L+e+gmVlIUp1Yi+NwOBxRJRwX0xBV\nPQCcB2wE2gK3RlOoykpct64A7JldKQwah8PhiCrhKAjPyhgOvKNWBvy4JGWg1WTaNdMFqh0OR/Un\nnHkQH4rIKszFdL2INAaORFesyknLQW04RC2yF7pAtcPhqP6UaEGo6h3AAKC3qmYDWVSCmc2xIO3E\nOFbGdSFxjVMQDoej+hNOqY3RQLaq5orIBOA1oHnUJauExMXBlnrpNNrhXEwOh6P6E04M4m5VPSgi\npwJnAy8AT0dXrMrLgZZdaXBsB+zaFWtRHA6HI6qEoyByfa/DgWdV9SOs9PdxiabbYnpHv1kSY0kc\nDocjuoSjILaKyDPAJcDHInJCmOdVS+qcngHA3mnfxFgSh8PhiC7h3OgvxmY1n6Oq+4AGHKfzIAA6\n9KvPKjqQ8+XXsRbF4XA4oko4WUyHgHXAOb4SGE1U9X9Rl6yS0rEjfBvXj5TV88GqzTocDke1JJws\nphuB14EmvvaaiPw+2oJVVmrUgO0t+5J8aCds3BhrcRwOhyNqhDNR7mqgr6pmAYjIQ8A84J/RFKwy\nk9O7H2yEvHnziWvdOtbiOBwOR1QIJwYhFGQy4Xsv0RGnatD0F+kcohYH/ufiEA6Ho/oSjgXxH2C+\niEz2bV+AzYU4bul5Sg0W0JvOc+fHWhSHw+GIGuEEqScCVwE/+9pVqvpYtAWrzHTpAgvi+pKyfjEc\nPRprcRwOhyMqhFQQIhIvIqtUdZGqPuFriytKuMpKzZrwU6t+JOQehSVuwpzD4aiehFQQqpoLrBaR\nlhUkT9Whb18A9GvnZnI4HNWTcILU9YHvReQLEZnqtWgLVtlpc3oLttKcrOkuUO1wOKon4QSp7466\nFFWQjAz4mn6cM99ZEA6Ho3oS1IIQkbYiMlBVZ/k3LM11S0kDi8iLIrJTRALWxhaRy0RkqYgsE5G5\nItLd79hG3/7vRGRBJB8s2qSnw7fSl6Sf1rnKrg6Ho1oSysX0GHAgwP79vmMl8RIwNMTxDcAZqpoO\n3A88W+T4YFXtoaq9w7hWhZOYCDta97ONb1zhPofDUf0IpSBSVbXY0mm+fa1KGlhVZ2NpscGOz1XV\nvb7Nr4EWJY1Z2ThhQAY5xKPzXBzC4XBUP0SDFJwTkTWq2i7IsbWq2rbEwUVaAR+qatcS+t0CdFTV\na3zbG4C9gALPqGpR68L/3PHAeIDU1NSMSZMmlSQWAJmZmSQlJYXVNxiTJ6dx5RMX06xbAqse/3uZ\nxvKnPGSLFk62yHCyRYaTLTJKI9vgwYMXBvXUqGrABrwJXBtg/zXAW8HOK9K3FbC8hD6DgZVAQ799\nab7XJsAS4PRwrpeRkaHhMmPGjLD7BuOrr1Sf5jo9Vruuam5umcfzKA/ZooWTLTKcbJHhZIuM0sgG\nLNAg99RQLqabgKtEZKaIPOprs7DifTeGpZpKQES6Ac8DI1V1j5/S2up73QlMBvqUx/XKm+7d4Rvp\nR8KhA7CsmDfO4XA4qjRBFYSq7lDVAcB9wEZfu09V+6vqT2W9sG/y3fvA5ar6g9/+OiKS7L0HhgAB\nM6FiTZ06sK7tObbxwQexFcbhcDjKmRLnQajqDGBGaQcWkTeBQUAjEdkC3Ask+Mb8N3AP0BD4l4gA\n5Kj5wVKByb59NYA3VPXT0l6/omjZtxmLNval15QpMGFCrMVxOByOciOciXIRoapjSzh+DRbPKLp/\nPdC9+BmVk4wMeOe1kfRacCds3QppabEWyeFwOMqFcEptOEJw6qkwhZG2MfW4r0DicDiqEU5BlJFe\nvWBXw078lNwWpkyJtTgOh8NRboQqtXFQRA4EaAdFJNAM6+OSuDg4Z6jwXs5IdPp0OOC+GofDUT0I\nlcWUrKp1A7RkVa1bkUJWdoYNg7cOj0Cys2HatFiL43A4HOVC2C4mEWkiIi29Fk2hqhpDhsA8BnCo\ndsPjy800dSqsXh1rKRwOR5QoUUGIyAgRWYMV15uFzYf4JMpyVSkaN4YevWsws8558NFHkJ0da5Gi\njyqMHQt//WusJXE4HFEiHAvifqAf8IOqtgbOworrOfwYNgxe2D0S9u2DOXNiLU702bEDDh2CtWtj\nLYnD4YgS4SiIbF8ZjDgRifNNnKuUJbhjydCh8KkOISchMbSbacIEGD264gSLFhs22KtTEA5HtSUc\nBbFPRJKA2cDrIvI4kBVdsaoeffpAzXp1WN70bFMQgarkbtwIf/+7HT92rMJlLFc8BbFrF+zfH1tZ\nHA5HVAhHQYwEDgE3A58C64DzoylUVaRGDQtWP3dwLGzaBC+9VLzTAw9YfCI7u+oHd9evL3jvrAiH\no1oSjoJoAtRU1RxVfRl4DkiOrlhVk6FD4el9Y8jqeSrcckvhpUjXrjWlcfbZtr10aWQX2bMH8vLK\nLGuZ8SwIcArC4aimhKMg3gH870i5vn2OIpxzDihxvDnoGTh40JSEx/33Q82a8OKLkJAQmYLIyoI2\nbeCf/yw/oSNlwwardw5OQTgc1ZRwFEQNVc13mPve14yeSFWX5s3tnvn64s5w223wyiswY4a5k157\nDX7zGzjxROjcOTIF8f33Nh7XYn4AACAASURBVFP7/ffLX/jSsn49dOliH9opCIejWhKOgtglIiO8\nDREZCeyOnkhVm6FD4csv4efr74KTT4brroO77oJateD2261Tt26RKQhvUaK5c2MbGM7Ohs2bzZpp\n184pCIejmhKOgvg1cKeI/Cgim4HbgeuiK1bV5dJLIScHXnmnFvzrX7BmDbz3Hvz+9zajDkxBbNtm\n8YTSsNy3blJODkyfXr6Cl4bNmy0O0ro1tG1rn7Ek1q61/m7lPYejylCiglDVdaraD+gMdFLVAarq\nHhmD0K0b9OsHzzwD+oshcMUV0LBh4XhEerq9lvZmuWwZ9OgBycnwaQzXUPIymDwFsWOHxVxC8dJL\nlubrSqI7HFWGoAsGicg4VX1NRP5QZD8AqjoxyrJVWcaPh1/9ylxNp/3nPxY3qFevoEO3bva6dCkM\nGhT+wMuXw7nn2o35009troXv96hQvAymNm0KrKB160x5BUIV3nzT3n/1VfTlczgc5UIoC6KO7zU5\nSHME4ZJLICXFrAji4gorB4CmTaFRo9LFIXbtsif19HQLdPz4Y+zmUmzYYBM/WrQwCwJCxyG++cas\njkaNLH5SGdJ0HQ5HiYQq9/2MiMQDB1T1vqKtAmWsctSuDZdfDu++GyTMIFL6QLXnjura1fJpoWQ3\nkyqsWhX+NcJlwwZo2RLi4wsURKg4xBtvwAknwD33WHD9++/LXyaHw1HuhIxBqGouEHJt6VCIyIsi\nslNElgc5LiLyhIisFZGlItLL79gvRWSNr/0yUhlixfjxcPQovPxykA7dutmNMjc3vAG9AHV6Opx0\nEnTsWLKC+OAD6NSp/APD69ebewkgKcksomAWRE4OvPUWDB9u7jEI7GZavRp+9zvr73A4KgXhZDF9\nJSJPishpItLLa2GO/xIwNMTxYUA7XxsPPA0gIg2Ae4G+QB/gXhGpH+Y1KwXp6dC/Pzz7bOCyTHTr\nZtVQ/UtWAKxbR8LPPxfvv2yZuWhSU2176FCYNQsOHw4uxJIl9jpzZiQfITgbNlgcxKNt2+AKYuZM\nc41deqkpldTUwArikUfgqafgu+/KV1aHwxEx4SiIHkAX4C/Ao772SDiDq+psIMDdLp+RwCtqfA3U\nE5FmwDnAZ6r6s6ruBT4jtKKplFx3nT0Yz54d4KB/oNojKwv696fj3/9evP/y5eZe8oLSQ4fCkSOm\nJILhxSjKMTAcf/iwxUPCVRBvvGFZV+eea7IPHFhcnuzsgsl/CxaUm6wOh6NshJPmOjhAO7Ocrp8G\nbPbb3uLbF2x/leLiiy0+/cwzAQ527mwBbH8F8fzzsGsX9RcuLDwRLi/PFISXHgtw+umQmBjazfTD\nD/Zajgoicft2e+O5mMAUxLZtpuD8OXLE5oBcdJFNFARTEBs2WH+P6dPBs5q+/bbcZHU4HGUjaJqr\nh4ikYO6e0327ZgF/UdVKUeNZRMZj7ilSU1OZGaY7JTMzM+y+ZeHss0/m7bfTOPfcb2nRorA7qE9a\nGlnTp/P94MHIsWP0e+ABaNSIE3bvZsWjj7LzTNPDidu30y8zk9UJCWz3kzm9Wzdqvf8+31xwQfEL\nq3LqihVIYiLxW7Yw7623OOq5p8pAHV+K68Kff+agT5bGx47RBfh20iSyTj45v2+jOXPoeuAAS7p0\nYa+vb3JiIhnA988+yy5fim+Hxx+nce3aHGzfnoSZM1kQ4e9SUb9pJDjZIsPJFhnlJpuqhmzAe8B9\nQBtfuxd4v6Tz/M5vBSwPcuwZYKzf9mqgGRYYfyZYv2AtIyNDw2XGjBlh9y0L27erJiWpjhwZ4ODo\n0apt2tj7555TBdWPP9aj9eurXnJJQb+pU+3Y3LmFz3/sMdu/YUPxsXfssGNXXGGvb7xRLp/nh9/+\n1sbbubNg58KFtu+99wp3HjVKtUkT1ezsgn1Hj6rWqqV6440F2/Xrq44bpzphgmp8vGpWVkSyVdRv\nGglOtshwskVGaWQDFmiQe2o4MYiTVfVeVV3va56yKA+mAlf4spn6AftVdTswDRgiIvV9wekhvn1V\njqZN4c47bY2gYtUxunWzIPX+/fDgg5CRAUOHsnvAAPj4Y0uDgoIspC5dCp8/ZIi9Biq74bmXRo2C\nOnXKzc1U66efbLxGjQp2elaDfxxizx7LorrkEpsz4VGzpq2u5MnzxRewd6/543r3tqwuL7hemXDZ\nVY7jkHAUxGEROdXbEJGBQIjUmQJE5E1gHtBBRLaIyNUi8msR+bWvy8fAemAtts7EbwBU9WdsLexv\nfe0vvn1VkptvtszUm28uktXqBarvvddmIt91F4iwZ+BAK13hmYjLl9sAdesWHrhDBwsAL1pU/KKe\ngujc2Wp/lJOCSNy+3eIP/jO4U1KszpS/gvjLXyz4fF2Asl0DB8LixRazePtt+1xDhpiCgOgHqjMz\noVUrU2DhMHky1K8Pu12NSsfxRTgK4nrgKRHZKCKbgCexAn4loqpjVbWZqiaoagtVfUFV/62q//Yd\nV1X9raqerKrpqrrA79wXVbWtr/0nkg9XWUhMtJVGly6F//h/Ek9BPPGE3chHjgRgb69e9pT+3//a\n8WXLCgeoPeLirLxFMAWRkGCKZeBAu3hJ9ZLC+SzbtxfOYPLwz2RavdoKFV57bXGrB0ye3FyrRTJ5\nMlxwgU2ka97cTK5oK4iVK4Ov+heIV14xpVIZLRuHI4qEk8X0nap2B7oB6araU1Xdf0opGT3a7ot3\n3WWlmQC7eScn20SJP/3JbvhA3gknWBrrlCnmZlq1ylJcA9Gzp924ik64++EHc/3UqGEXzsuDr78u\n24dQpVYwBdGuXcFs6ltvtayl+4JMuO/f317//Gdzr118sW2LmBURbQXhKbJp0yzTKhSHD8P//mfv\nozEr3eGoxJSoIETkD76CfdcA1/i2rxaRIJXZHIEQgX/8A3buhL/9zW9nr152wx0zpvAJI0fC9u3w\n+uvm/w5kQYCdf+hQ8VIXP/xgLigwF1NcXNndTLt2EX/kSOEUV4+2bWHLFvjoI3Pd3HVXwaS+otSv\nb5bF119bHvAvflFwrHdve8IvB2snKJ6CyMqyBZ1C8fnn9v1C5VAQa9eatfnjj7GWxHEcEI6LqTfm\nUvLmJ1yHTVp7TkRui6Js1Y5TToErr7RJw/kZaN6qczWKZBwPH261jjxtEsqCgMJuptxcu5G0b2/b\ndeuagimrgvCquAZzMYGVsW3VCm68MfRYAwfa64UXWuDa45RTzKJavLhssoZi7Vpo0sTceCWVH58y\nxb6/7t0rh4L46CNToJU0vdJRvQhHQbQAeqnqH1X1j0AG0ASbF3FlFGWrljz+uHljLrnEHrhp2dJc\nTUVp0ADOOMOC1zVqWO2lQHTqZP57/xvq5s3mmvIUBNgN+euvy5aNE46C2LkTHnrIAi+hON03rcZz\nL3lkZNhrNN1M3lP4OeeYtROwFgqmaD/4AIYNs3jRypXRkylcPDdhJCsSOhylJBwF0QQ46redDaSq\n6uEi+x1hULeuVZU4dMjiEseOhejsC1rToUPhp2x/EhLMOvBXEF4GU1EFkZlZtsJ94SiIAQPsg5XE\nJZfAJ58UVKb1SE21dbujrSDatoURI2Dr1uDWyvz5pvBGjjQFvXVrdF1f4TB/vr2Wl4L4/ntqb9xY\nPmMdz8ydWy1XSwxHQbwOzBeRe0XkXuAr4A0RqQOsiKp01ZROneDFF+1h8A9/CNHRUxDB3EsePXua\ni8l7Eg6mIKBsbqb16zlWv765ZopSv75VJnzllfAWMapRwwLxgfpGM1B94IDd9Nu2LagPFczNNGWK\nyTlsmP1oELs1OMDk9tbiKC8FcckldHgkrNJqjlBceWUJ/8xVk3CymO7HSlns87Vfq+pfVDVLVS+L\ntoDVldGj4Y9/tAKmQUuCn3QS3H8//OY3oQfr1csmm3mByx9+sOwo/yBxy5aQllY2BbFhA0eaNg1+\n/NprCybNlYXevS3ovm9f2ccqyrp19tq2rc3dGDAgtIIYNMgC6Z6LL5ZxCM96GDHCKuTu3Fm28bZt\ng++/p8769cHdbI6SOXbMJrx6D2bViHAsCIBEbOGgx4FNIhLAx+AoLQ8+CIMHw9VXwzvvBOk0YUKB\nvz4YRQPVP/xg1oP/03mwSqrhcuwYLFxIVqtWkZ1fGrwJc4Hmd5QVL4PJc4mNGGEups2bC/dbvdqa\nZ8WdfLIlDcQyDjF/vslw5ZW2XVaXxhdfAFDj8GGXFVUW1q2zeNXmzSWnTVcxwklzvRe4HfiTb1cC\n8Fo0hTpeqFHDHlL794exY21dnYhIT7c0Vs+X7imIopx+uv0Rr4jAM/j557BvH7tOOy1CIUuBpyCi\nUdnVUxCepTNihL1++GHhflOmFD5es6YplVhaEF9/bdlUffvadlndTJ9/XvDerfIXOZ7bUbX4+i5V\nnHAsiAuBEUAWgKpuw61JXW4kJ1usdsAAW1PnzTcjGKR2bfORL15s2UsbNwZWEKNGmVYKdwaxP++8\nAykp7PVu3tGkQQObaxGNOMTatTZbOynJtjt0sLSyom6mKVPMMmvZsmBfx46xUxB5eaYw+/a1FN3U\n1LJZEKqmILw5KE5BRI6/aynU0rtVkHAUxDFfxT8F8AWnHeVIUpLV5jvtNBg3DqZNi6AstxeoXrfO\n/vkDKYjUVDjvPAskZ2eHP/axY1b2Y+RINCGh9LJFQu/e0bMgPPcSmOttxAgrePjZZ1b649lnYd68\nAveSR8eOdgOIReG+VasswO5ZD6Vd0zzQeNu2wejRHG3UqGBJW0fpWb264IHjOFQQb4vIM9hqb9cC\nnwPPR1es44+kJJsDNXgwPPhgJx58sJRxw5497R/+yy9tO5CCAJvItmOHmS3h8sUXFjAOJ321vBgw\nwOolBVupLlKKKgiwWlDHjlnBwIsusgKDNWoU/7ydOplijYUbwZv/0K+fvaanl25N86J47qWzz7a4\nkrMgImf1aksUadjw+FMQqvoI8C62LkQH4B5VfSLagh2P1KljSuLMM3fwpz/Bb39biv//Xr5lwidN\nstdgCmLYMHOxvPBC+IK9845N4PAviRFtLrzQXt99t/zGzMoyJVpUQZx6qs1mnz7d3HQbN1pWWOfO\nhfvFMpNp/nzLpmrXzra7dbOAaKQK9PPPzY3XurUpiJUrzY1VWn788fjIgLIVTwIf82J+oZberaKE\nE6R+SFU/U9VbVfUWVf1MRB6qCOGOR044Ae66ayW33w5PP20PtF4poJD08JXGmjnTFEDR0uAeNWrA\nL39pmuinn0oeNzvb3EsjRphwFUXLluZOCZreFQHek39RBQGWzjp4sH2PJ50UeK6HV9sqFgri669t\nHQ1fQceAa5qHS06OKUSfwj/UqpX9kZV2wtyaNTZp8r33Si9DVeOuu+z7L8revbZGuxfLOt4sCCDQ\nY+Ow8hbEUUBcnKXAPvmkVXro1y+M7Mp69eyfNVj8wZ+rrjLT5NVXSxbGW9CnIt1LHqNHW1ylvFw6\nRVNcS0u9eqZ8KzrVNTPTYgSeewnM3RUfH5mC+PZbmxF+9tkABanLgdxMP/4Y/Anl88/N6pg1q/Qy\nVDU+/dSSJnbsKLzfy2DyFMTmzVYBuChPPBHbSZYRElRBiMj1IrIMW+xnqV/bALhCMBXAb39roYKf\nfrISRc8/X4I177mZSlIQHTrYnIgXXyzZPfDuu5Zq5a1eV5H8v/9XIEN5UDTFNRI6dap4C2LhQrsR\newFqsFpX7dtHpiA+/9yC84MHA5Dl1QIrqiCOHDFL5a67Ao8ze7a9BksmWLfOfsOqUDfqxx+tMGYg\nN9uRIwUZY/PmFT7mX7XAc/95kzE9Nm+24pX//nf5ylwBhLIg3gDOx5YFPd+vZajquAqQzYGVKlqy\nxGK2115r8yWCTjD2JsyVpCDAgtWrVoVeIyI727J6RowoufheNGjVyqq7lpebae1aWyq1Xr3Ix/BS\nXSvS7+79Rv4KAuzmHUmq6+efFwRVgdykJKt/VTSTafp0W68j0Mp7qgWWw3ffBS4q9tprVnisf//y\ndRVGg+efN0UYaFGo774ryFybO7fwsdWrzW3bpk2BgijqZvKUShV0PwVVEKq6X1U3+laF24QtM6pA\nkoi0DHaeo/xp1szWrPnb3+xhukuXINUhvEqonq88FKNHm5/9mWeCp23OmAE//xwb95LHqFFm2pdH\nQblAGUylpWNH09BFXQ3RZP58k9t3Q88nPd1qM+WvQBUGmZl2w/K5l/Lp0qW4BeEphnXrigdf162z\n9UoGDbK5N4HSZOfMsYeVHj2sau+f/hR51lW0WbjQXufMKX7Ms5BatSpuQaxebcohIaHgb6vod+Up\nleqkIDxE5HwRWQNsAGYBG4FS5Eg6yoO4OPv/mj/fHoJHjrQ1hgqV4xkyxJ7azj235AGTk22Al182\n66B1a3M5jBoF559vN5Dx461f0YqrFcmoUfZaHm6m8lAQXtG+inIzqZoFUdR6gIJAdWnmMMyZY5Zh\n0Yy0Ll3sM3k3cFWbXd69u21Pm1a4v2c93HKLvRZ1M2Vn2810yBB70Bg/3gJrF1wQWbZUNFEtWUE0\na2aZdQsWFLaW/KsW1Ktn/5xFFYGnINavj80cmjIQTpD6AaAf8IOqtgbOAsJau1JEhorIahFZKyJ3\nBDj+DxH5ztd+EJF9fsdy/Y6VsKrL8UNGhv293n+/eX86dzbLYudOTItcdlnxxYeC8cQTZlrfcYf5\nsI4dszIcW7daoO3kk+Gvf42Ne8mjTRtzh5TVRXHkiPmCy8OCgOgriNxcuwn/+tf2pB5KQZTGzfTZ\nZ/Z7etV9Pbp0se/ISwhYssQWLLnxRvsNiiqI2bOt2OGwYWbZFFUQixdbcPu006xMyTPPwAMPmNLx\nig6WRE5OxVgc27aZRVizpimIou7Db781V+eAAfYdffed7c/LM2Xgb7EXzWQ6fNi+i2bN7PNs2hT9\nz1OOhKMgslV1DxAnInGqOgNbZS4kIhIPPIVlPHUGxopIocRyVb1ZVXuoag/gn8D7focPe8dUdUS4\nH+h4oGZNq+G3eLHdO++6y1zIl18e/v8eYCU6rr7a/nFff90K+a1YYZlDX31lGUy//33UPkfYjB4N\n33wT+p9r3z7iAmWPeGzYYP/4ZVUQLVqYay5aCiIvD+6+29J8Bw2yTLOxY+GKK4r3bdnS0pnDDQKr\nmtvojDOKK/0uXezVczN98IEFsocPNwty+vTCT86zZlltr7g4u3l+803h8bwncf/aXb/7nbli/vvf\n8GQdNoxudxR7rix/POthzBhTFP4uogMHzI10yikFa6n73EyJO3eawgilIBYsMMUwzhe2rWJupnAU\nxD4RSQJmA6+LyOP46jKVQB9graquV9VjwCRgZIj+Y4FIKhEdt3TubLGJFSvMgp8yxTIhhwyJTpWK\nmOG5mQLl26vaTbRVK3recIP5wwNR1hRXDxGzIkqT6rppE0lr14YX2P7Pf0xh9+hhhbl27oQ33oCU\nlMCypKeHryC+/96+B28Soj/epEB/BeHVfTrnHJtk6FUC3rTJmldl+JRT7Lwsv9vCnDlmgTZrVrAv\nJcXcmJMnl/xdTJoEn39OgwULor8Qz8KFpuh+9zvb9nczLVxosp5yipXLP/HEfJdRLa8Crn9SSLt2\nZoF7qcGee8lT8NVQQYwEDgE3A58C67BsppJIA/xrKG/x7SuGiJwEtAam++1OFJEFIvK1iFwQxvWO\nWzp1gn/+0/4uH33ULIs+fczdWy0WuWrb1m6YTz1ldaR+/tn279plyuOKK6BlS5LXrg2eklleCgJK\nV7Rvzx7o14/e115rN5irr7bMnkDWzr59FmgaONBcMWPGFNT4CYaXyRSO8pk82ZRK0RpTYNc56SSL\nZ2zfbk8Y551nxwYPNrel52bybqBnnGGvp5xilo9XTTgvz0q+BCpTf8EFdpMM9f1lZsKtt0J6OnkJ\nCTZjNJosWmS/ae/e5i7zVxCeZeQVqRwwIN+CqL1li+3ztyC8vy8v1XXuXFMgXbrYd1zFFERQZ7WI\ntMWWFvUWEMgDXhaRU4F6wJ5ylGMM8K6q+jscT1LVrSLSBpguIstUdV3RE0VkPLagEampqcwMczH3\nzMzMsPtWNGWRrVcvePnleN59twVvv30iU6bU4KSTsujT52f69v2Z9PR91KwZeYpmrL63hhdfTPuJ\nEznhl79E4+LY16MHdTZsoEZmJhuuu47No0fT6tFHafXooyxp1oy9XkaXj3azZtEkKYmvli4Nb8W7\nEJyYlMTJP/7IdxMnss+bexKETvffT+Pdu1n1q1/RaP16Grz1FjVefJEDHTuy5NFHya1dO79v2yef\nJG33bhb+9a9khjn5rFliIh3272f1H//I9hGhPbEZr75KXufOLF61qtAN2vtN05s25YRvvmHrxIl0\nAL5t2pQs32/do0sX4t97j4VDh9J+0iQaJyXx1e7dMHMmNbOzGQCsffNNtuTkUHvjRvrs2cOqxo35\nqcjfSs1GjRgArH/0UX4cFzhbvvXzz3PS1q0suuMOGk+eTLOXXmLeeecV+q7Kk/7z5rG3Vy9WzZpF\n144dqfO//zHfJ3eXjz8mqXlz5vuetNIaNaLd5s3Me+cdmq1fT06dOny5cmX+95m0fz+9geWTJ7N7\n924GzJrFnv79WT1rFhlNm3Js/nyWVcD/T7n9n6pqwAZ8CKQH2J8OfBDsPL9+/YFpftt/Av4UpO9i\nYECIsV4CRpV0zYyMDA2XGTNmhN23oikv2fbsUZ04UfUXv1CtWdOKySQnq95wg+oPP8RWtojIzVWd\nP1/1jjtUO3VSHTBAdenS/MOzPvnE9jdrprp7d+FzhwxR7d27fOTIzFTt2FG1aVPVHTuC93vrLfvS\nH3ig4Hs7dkz11VdV4+NVzz5b9cgR279sme277rrSyXLwoH02UP3Nb2z8QGzYYH0efrjYoXzZbrvN\n/lCGD1dt2VI1L6+g09/+Zudv367avr3q+ecXHqRFC9WxY+39v/9tfdesCSxLnz6qp5wS+NjatSbD\n5ZerquqCp56ysf71r8D9y8q2bTb+Y4/Z9iOP2Pa2bbbdsqXqJZcU9J8/346//bbuycgo/je1f78d\nf/BB+ycD1WeftWOjR6uefHJ0PkcRSvN/CizQYPfeoAfg2xDHlgU75tenBrAecx3VBJYAXQL064il\nzorfvvrACb73jYA1QOeSrukURHAyM1U//FD1sstUExLslx82THXqVNVDh2IrW3kxY8YM1cWL7QNe\ncIHd4PLyVLdutX/0MWPK72JLlqiecILqOeeY4irK9u2qDRvajTA7u/j39tJL9iOMGqWak6M6eLBq\n/frFFVs4ZGer3nKLjXf66YGV1j/+YcfXri12KF+2l1+2PiKqv/1t4U4LF9qxhx4KrGguvFC1bVt7\nf9llpjz9FYw/nrLZvLn4sREjVJOS7DdT1RnTp6v27Kmanh58vLLwwQcmy5w5tu0pgLfesu8RTGl4\nHD2qmpioevPNejg11T5rUZo0Ub366oLvc/ly23/nnfYQEEiJR/K7h6C8FESoGESo6aa1wrBMcoDf\nAdOAlcDbqvq9iPxFRPxt4THAJJ+gHp2ABSKyBJgBPKiqESyD5vCoU8cSUl57zaoK3HefuYxHjLD1\neYYPNxd/lV95skcP+L//s0yZjh3N75uWZh/My9QpD7p1g8ceM7/8I48UPqZqJcOzsixmEijt+Je/\nhIkTbX6HV032gQeKT4YLhxo14OGH7cf95hsLLu/eXbjP5MkW0A5VZsT7flRtLow/PXpYwPohX51O\nL/7gccopFufZu9d8+KedFtyVd4EvpFh0tucnn9i+u++G5s1tn4ityb5sWdnWUw/GwoV2Da/YZc+e\nlt03Z05BpscppxT0r1nT4hFffEHijh2BJ6V6mUxz51pg3ps7066dpe1u2FC4/7Jl9t0GK3qYmxu7\nYGIwzYFlFF0bYP81wFvBzotlcxZE6Th6VPXTT1VvvNEe/ryaxmeeqfrKK2Z1xEq2SMiXLTdXdfx4\nc5XcdJPqk0+qTptW4M4pL/LyzAKoUcPGnzfP3EfXX29f5D/+UVy2otx5p/Xt3t0sibIyb15hC0rV\nnoRFVO+5J+Ap+bJlZVm/OnUCf1fjxpmsSUlmtfjz2Wd27Pnn7fWJJ4LLmJdnbqpf/KJg34oVZnF1\n6FDo2jNmzLA/xJQU1UsvDf3Zt20LbM2F4vzzzV3oz1ln2e9x772qcXHmxvPn1lsL/lkmTSo+5pVX\nqjZvblbPOecU7P/ySzvnww8L9/esss6dA8t/++12fMKEwFbUzp2q//tfoV0V4WJKBeYCM4FHfW0W\nMA9oGuy8WDanIMrG6tWq999vblLvPnDppWYpb98eW9nCISay7d2r2qpVwQ3Dc9FcdFGhf/agsuXl\nqb7wQuRBoUB4fvTnnrPt556z7cWLA3YvJFt6enBX3Kuv2jj+Nz2PvXvtWJcuIa+Vz223mWLdu1d1\n0yaLYaSmFnOB5ct2ww2m+ILFfNasMZffVVeFvm5Rmjcv7ib685/tNxw40D5PUSZPLvitA33OBx4o\n+Du4776C/Z7Lyu/BQVXN1+v5fd96q/CxDRssJtOsmR2/9toC5ZyXp/rGG6qNGqk2aFDoiS7qCiK/\nAwwGfu9rZ5bUP5bNKYjyIS9PdfZs1V/9SrVx44L/hW7dVEeN+lHfey90bDZWxOx727DBrJQPPlBd\nuVL18OFiXSpUttxcewquXdu0/rnnmhIL4sMvJNvOnaoHDgQed8cOuwk/+mjg4+3b2x9K3bolW0Pz\n5lnfxx83q6Fu3YA323zZVqyw/n/9a+DxLr+84A+16BN6MLZvt/4TJxbe/8UXBWNdeWXx8376qeB4\nIDPbS04As6w88vLsc/7mNwX7srPtSWz8eEuw6NKlsBUxZoxqrVoWr5kwwca84AJTiOedZ9t9+xbE\nOXxUmIKoSs0piPInN1d10SJLyhg8WLVmzZz8v/327e3h6+GHzcLduTO2slam760oFS7bli32VNmz\npz2B3nxz0K6lkm39PE4nqgAAEU9JREFU+uCZUpddpvnZDyWRm2uBbLCg76xZJcs2bJil4f34Y+FO\nK1bY0/oNN6h27WpP2z//XLIMH31k1y967awss25A9amnAp/burUebtw48LFFi+zcuDjLavInI6Ow\na+3rrzXfcnjzTfUypFS1QInefXdB/yeesM8K9gDwj38EVMYVEaR2OIiLs7jd7bdbtYUPP/ySuXPh\n73+3+NzMmTanacgQi7O1aWPx1+eftzpmGvmUC0dZSEuzH2HxYiuREWj2dCS0bm3lMgLhBXP9y2sE\nIy7O1oqIj4e33w48qa4oTz5pAdtf/7rwH9af/2yB5QkT4KWXbPb5TTeVPJ4XoPbK5HvUrl1QGdk/\nQO3PTTexLdi8E2+yXHp68ZUdi5bi8OYqnHGGlZTp2BH+8hf7nH/4gy1QddttBf1//3v7vi67zALX\nN91k32GUcArCUSoSEpT+/U0pTJ1q9dx27bIlBh5+2JJBPv7Y1q7wFtm67TYrSFrZinhWey680DKA\n2rSxGcDR5uyzrcZTONWEwf5gVq4snjEVjDZtrHjkxx9b7TCwMiNvv203ysaN7cZ+552WPRZoHQt/\nFi60Wc7JycWPDRliN3evIGJRbrgh6EQ/kpPtRh+oCnL79pZR55WEmTnTypykptqN/u67bTb7FVfY\njO377y8+m37UKMtYa9Mm9OcrB8Is++lwBKdRIzjrLGtgD3erV1vm5pQplg368MP2MNStmz1gtW1r\n5fVr1bIszYQEq5acnl6w7LKjHPCeuqP4lJlPly5Wgyjcmeq1ahUsshMu3hP0jTdayfJ77rFU0j/+\nsaDPhAn2hzd+vJXR8K8H5c/ChcGtnTvvtPMjXYd94cLAlla7dvaktH69/RPMmWMmt8cll5gF8cYb\n9s9w1VWRXb+ccArCUe549ew6doTrr7cSQx99ZGnuq1fbw9/+/YHPbdLE5mScd56VAKpXr8yVMY5v\nRMIv/15e14sm8fHwwgtmqo4caeWL77sP6tcv6FOzpq1z0q+f/RHec48plpo1C/rs3Gnmb5GSLPkk\nJlrl3kgJVhbEf9W5/fttrsygQYU/3333WQXfRx+tGMUeAqcgHFGnXj1zmV52mW2rWr29TZvM0s7J\nsbZ1q3kPJk+2oqZg/x8pKTZGy5bmqh40yP73a5U4XdNRLenUyW76EybYLM9A8YYePWxNiz/8wRY1\neuYZezI/fNgmwHmT7oIpiGjhryBW+Ob+Fp10eMkltq9p04qVLQBOQTgqHBGbMBxo0vC4cbYY2Vdf\nWSn9ffsK2urVNtn4L3+xh8GOHW2MBg2sHT3aig0bzHXVqpXFaf0fGh3ViNtuM1/9eecVDwR7dOhQ\nYLrefLM9lYPFCDIyTMGcemrFyQwFf6xr1tiM6i5dzGwuSiVQDuAUhKMSkpBgVoK/5e2xf79Vkp45\n07Kkfv7Z4px79sCuXSfxyisFfUUs9peWZt6CjAyLk5xySvBEHEcVISHB1ssIh2HDLIA+Y4aZoe3b\nxzbQ1a6dWQ8LF8Y8xlASTkE4qhQpKRajGD68+LHPPpvNySefwcaN9nC2ZYu1rVtNmUydap6J5GSL\nTTZubPeJ+Hi737Rvb0swd+9uD3mOakRCgmUmVQbatbNAnKoF2ioxTkE4qg0JCUqbNsGz//bssYfI\nL76w5JHvv7cEn7w8c03v3VvQt2lTK3CYkGCtTh3o2tVc2z162DUOH4aDB219GxF7OG3WLOZxRUdl\np127gnkc4cz/iCFOQTiOGxo2tBRybwXTouzYYXHNJUss3nHkiM0xy862GMj779vcs1AkJJg766ST\nrLVsaW3fvvqkpdn7SDMnHdUEL1DdtauZsZUYpyAcDh+pqeaFCOaJUDV31XffwebNZlUkJVnLybH5\nT95yzZs2maWybZs3QbA7t95q4zRrZvHTbt2spafbtWvVsuzIWrWcFVKt8RREJXcvgVMQDkfYiJh1\nUJr0+Oxsi4NMmbKY+vV7smkTbNxogfUXXrA0+EAkJVlqf4MGluJbo4ZdX8SslNatLYurQwebiJsW\ncLV3R6Wka1cYOtRmS1dynIJwOKKIdzPv0WN/saysvDwLpi9bZtlYhw/bRORDh8yltXdvQTt8uKCe\n+JEjFkM5eLBgrBNPtMD7aafZuuSJiWaFxMdbqm/duta8tF/VgusdPeqmrlcoiYmWelsFcArC4YgR\ncXG2wFuoRd6CoQo//WSxkqVLLfV3+nSr0BCKmjXNGjl0qGCfyGmcdJJZJJ06mbsrMbGgxcUVKCcR\nC9B37x64hJGjeuEUhMNRBRGxWEazZjZf5IYb7Aa+fr1lZ+XkWIZWTo7NVj940NqBA7avTh2Ld9Su\nDYsWbeTo0dasWgWzZpllEc7127a1GEr9+hZ4T0w0BaRq1lFenvWrU8esl+Rki8n27Vtp5oE5SsAp\nCIejmiASmUUyc+YmBg1qDRS4sLzmuba88XNzbU7J4sXWli0zxXP0aEGLiytoeXk2TlFat7YCs+3a\nWfrxzp3WcnNN6TVvbu3HH9OYO9dSiTMz7bONGuViLhWFUxAOhyMfEcuiClXnql27wBMVg5GTYzf3\ngwctYD9vHsyda1ler79uQfjGja3iRFycTTD+4APPDWYZPzVqmCWyf79VzTj9dCtZ1KxZgXLZtcuU\nWWJigUVTp45ZLl7zjnktIcGsHm+ui3/NP0eUFYSIDAUeB+KB51X1wSLHrwQeBrb6dj2pqs/7jv0S\nmODb/4CqvhxNWR0OR3SoUcOUQL16Fkzv399q6Kma8ghU9kTV3GEzZ37F0KEDqVnTlNfq1TBpkrXf\n/KbwOXXrmoLxLJlI1h+pX99m1Ldvb/NY6tYtSGWuXduUSs2a1lauTCYtzc6pV88SAnJybO7MsWMF\n/asyUVMQIhIPPAX8AtgCfCsiU1V1RZGub6nq74qc2wC4F+gNKLDQd+5eHA5HtcBL2Q12LCUFUlKy\nC91kO3SAe++1kikrV5oiaNLELJCihRmzswsslwMHirvCjhyxPl47cADWrjUX2owZZu2EpuRKsF7c\npXFj+zxeLCYpqXAVdi9W41k6desWVDGuV6/g3KSkii0jFU0Log+wVlXXA4jIJGAkUFRBBOIc4DNV\n/dl37mfAUCDM6lwOh6M6I2LzP0KRkGBP95G6jfLyzM3lxT+yskyReBbCvHnLaNEiPT8VOTfXlJTn\nusrKMreX1/btswmWXsKAv4WTm1s4sywUdeoULgOTkGBB/9mzI/ucoYimgkgDNvttbwH6Buj3/0Tk\ndOAH4GZV3Rzk3IBhKREZD4wHSE1NZaa3xmsJZGZmht23onGyRYaTLTKcbJGRnp5JUtIeTjyxfMbL\ny4OjR+M5dCierKx4srJqkJlZ0A4fjufQoRocOhTPkSPx5OQIOTlCbq5Qq1YuM2f+kD9WuX1vqhqV\nBozC4g7e9uVYjMG/T0PgBN/764Dpvve3ABP8+t0N3FLSNTMyMjRcZsyYEXbfisbJFhlOtshwskVG\ndZENWKBB7qnR9GZtBfx1awsKgtEAqOoeVfWt3s3zFDj1SjzX4XA4HNElmgriW6CdiLQWkZrAGGCq\nfwcR8V9NfASw0vd+GjDk/7d3byF2VXccx78/kxpNIrloFE3EaBVvRUeREC8tXuqVkvbBUq9EEXyJ\naESwDlWL6ZMgXh6kWmparSFKNGlDEK1OJaBgYhJHndyaqFFH1In32lIx8d+HtU5zHHfieDIzeznn\n94HD7L3Ohd+cvff8z157zlqSJkmaBJyT28zMbJgM2TWIiNgm6RrSH/ZRwPyIWCtpHumUZilwraRZ\nwDbgI+CK/NyPJP2OVGQA5kW+YG1mZsNjSL8HERFPAE/0a7u1abkT6NzJc+cD84cyn5mZ7ZyHcTQz\ns0ouEGZmVskFwszMKrlAmJlZJUVjLN8RQNJW4M0BPnw/4IMhjLM7nK01ztYaZ2vNSMl2SERMqbpj\nRBWI70LSqog4qe4cVZytNc7WGmdrTTtkcxeTmZlVcoEwM7NK7Vwg/lB3gF1wttY4W2ucrTUjPlvb\nXoMwM7Nda+czCDMz2wUXCDMzq9R2BULSeZI2Stos6aYC8syX1Cepp6ltsqSnJW3KP1ucNHG3ch0s\n6VlJ6yStlXRdQdn2krRS0ss52225/VBJK/K2fTQPM18LSaMkvSRpWUnZJG2R9Kqkbkmrclvt2zTn\nmCjpMUkbJK2XdHJB2Y7M71nj9pmkuSXkk3R9Pg56JC3Mx8eg7G9tVSAkjQLuBc4HjgEulvQtM9sO\nuT+T5ttudhPQFRFHAF15fbhtA26IiGOAmcCc/F6VkO0L4MyIOB7oAM6TNBO4HbgrIg4HPgauqiFb\nw3XsmN8Eysp2RkR0NP2ffAnbFOAe4MmIOAo4nvT+FZEtIjbm96yDNLHZf4AldeeTNBW4FjgpIn5E\nmlrhIgZrf9vZVHMj8QacDDzVtN4JdBaQazrQ07S+ETgwLx8IbCwg49+As0vLBowF1pDmO/8AGF21\nrYc50zTSH4szgWWACsq2BdivX1vt2xSYALxB/seZkrJVZD0HeL6EfMBU4G1gMmn6hmXAuYO1v7XV\nGQQ73syG3txWmgMi4t28/B5wQJ1hJE0HTgBWUEi23IXTDfQBTwOvAZ9ExLb8kDq37d3AjcBXeX1f\nyskWwN8lrZZ0dW4rYZseCmwF/pS75v4oaVwh2fq7CFiYl2vNFxHvAHcAbwHvAp8Cqxmk/a3dCsT3\nTqSPALX9L7Kk8cDjwNyI+Kz5vjqzRcT2SKf704AZwFF15OhP0s+AvohYXXeWnTgtIk4kdbPOkfST\n5jtr3KajgROB30fECcC/6dddU/exAJD78mcBi/rfV0e+fM3j56QCexAwjm92Wbes3QrEO8DBTevT\ncltp3m/M151/9tURQtIPSMVhQUQsLilbQ0R8AjxLOo2eKKkxS2Jd2/ZUYJakLcAjpG6mewrJ1vjE\nSUT0kfrQZ1DGNu0FeiNiRV5/jFQwSsjW7HxgTUS8n9frzvdT4I2I2BoRXwKLSfvgoOxv7VYgXgSO\nyFf49ySdKi6tOVOVpcDsvDyb1P8/rCQJeABYHxF3FpZtiqSJeXlv0rWR9aRCcWGd2SKiMyKmRcR0\n0v71j4i4tIRsksZJ2qexTOpL76GAbRoR7wFvSzoyN50FrCshWz8Xs6N7CerP9xYwU9LYfMw23rfB\n2d/qvuAz3DfgAuCfpD7r3xSQZyGp7/BL0qeoq0h91l3AJuAZYHINuU4jnS6/AnTn2wWFZDsOeCln\n6wFuze2HASuBzaQugDE1b9vTgWWlZMsZXs63tY39v4RtmnN0AKvydv0rMKmUbDnfOOBDYEJTW+35\ngNuADflY+AswZrD2Nw+1YWZmldqti8nMzAbIBcLMzCq5QJiZWSUXCDMzq+QCYWZmlVwgzAog6fTG\nyK9mpXCBMDOzSi4QZt+BpMvyXBTdku7PgwZ+LumuPCZ/l6Qp+bEdkl6Q9IqkJY25AiQdLumZPJ/F\nGkk/zC8/vmk+hAX5m7FmtXGBMBsgSUcDvwJOjTRQ4HbgUtI3bFdFxLHAcuC3+SkPAb+OiOOAV5va\nFwD3RprP4hTSN+khjZg7lzRXyWGkMXXMajP62x9iZtlZpMliXswf7vcmDc72FfBofszDwGJJE4CJ\nEbE8tz8ILMpjIU2NiCUAEfFfgPx6KyOiN693k+YJeW7ofy2zai4QZgMn4MGI6Pxao3RLv8e1On7N\nF03L2/HxaTVzF5PZwHUBF0raH/4/l/MhpOOoMXLmJcBzEfEp8LGkH+f2y4HlEfEvoFfSL/JrjJE0\ndlh/C7MB8icUswGKiHWSbibNyLYHaQTeOaTJbWbk+/pI1ykgDbN8Xy4ArwNX5vbLgfslzcuv8cth\n/DXMBsyjuZrtJkmfR8T4unOYDTZ3MZmZWSWfQZiZWSWfQZiZWSUXCDMzq+QCYWZmlVwgzMyskguE\nmZlV+h833o7TwZmVggAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o33QWvDUBhgl",
        "colab_type": "code",
        "outputId": "c7228dc0-83ea-466c-f34f-504e66b5f138",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "import pylab as plt\n",
        "def plt_dynamic(x, vy, ty, ax, colors=['b']):\n",
        " ax.plot(x, vy, 'b', label=\"Train accuracy\")\n",
        " ax.plot(x, ty, 'r', label=\"Validation accuracy\")\n",
        " plt.legend()\n",
        " plt.grid()\n",
        " fig.canvas.draw()\n",
        "fig,ax = plt.subplots(1,1)\n",
        "ax.set_xlabel('epoch') ; ax.set_ylabel('Accuracy')\n",
        "# list of epoch numbers\n",
        "x = list(range(1,80))\n",
        "vy = history.history['acc']\n",
        "ty = history.history['val_acc']\n",
        "plt_dynamic(x, vy, ty, ax)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRAd9EirjAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUiCfgaBTA7W",
        "colab_type": "code",
        "outputId": "8a285fc3-a48f-43e1-eedf-c8cd611bdb2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Test Accuracy {}\". format(score1[1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy 0.902899980545044\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrfMV8tw8qNm",
        "colab_type": "text"
      },
      "source": [
        "#### Test Accuracy = 0.9029\n"
      ]
    }
  ]
}